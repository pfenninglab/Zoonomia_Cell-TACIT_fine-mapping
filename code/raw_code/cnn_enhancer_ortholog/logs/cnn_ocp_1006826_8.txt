Running cyclical learning rate for OPC_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.05.
In training mode.
There 164974 positives and 145248 negatives.
There 22612 positives and 20082 negatives.
Epoch 1/23
311/311 - 192s - loss: 0.6948 - accuracy: 0.5388 - macro_f1: 0.4873 - val_loss: 0.6875 - val_accuracy: 0.5707 - val_macro_f1: 0.5640
Epoch 2/23
311/311 - 191s - loss: 0.6846 - accuracy: 0.5692 - macro_f1: 0.5482 - val_loss: 0.6809 - val_accuracy: 0.5824 - val_macro_f1: 0.5640
Epoch 3/23
311/311 - 191s - loss: 0.6813 - accuracy: 0.5784 - macro_f1: 0.5632 - val_loss: 0.6735 - val_accuracy: 0.5966 - val_macro_f1: 0.6220
Epoch 4/23
311/311 - 191s - loss: 0.6784 - accuracy: 0.5871 - macro_f1: 0.5798 - val_loss: 0.6755 - val_accuracy: 0.5967 - val_macro_f1: 0.6844
Epoch 5/23
311/311 - 191s - loss: 0.6754 - accuracy: 0.5923 - macro_f1: 0.5890 - val_loss: 0.6714 - val_accuracy: 0.6014 - val_macro_f1: 0.6206
Epoch 6/23
311/311 - 191s - loss: 0.6722 - accuracy: 0.5997 - macro_f1: 0.5986 - val_loss: 0.6688 - val_accuracy: 0.6057 - val_macro_f1: 0.6423
Epoch 7/23
311/311 - 191s - loss: 0.6700 - accuracy: 0.6042 - macro_f1: 0.6061 - val_loss: 0.6648 - val_accuracy: 0.6113 - val_macro_f1: 0.6865
Epoch 8/23
311/311 - 191s - loss: 0.6700 - accuracy: 0.6035 - macro_f1: 0.6058 - val_loss: 0.7099 - val_accuracy: 0.5482 - val_macro_f1: 0.3427
Epoch 9/23
311/311 - 191s - loss: 0.6664 - accuracy: 0.6106 - macro_f1: 0.6135 - val_loss: 0.6807 - val_accuracy: 0.5881 - val_macro_f1: 0.4967
Epoch 10/23
311/311 - 191s - loss: 0.6628 - accuracy: 0.6149 - macro_f1: 0.6206 - val_loss: 0.6846 - val_accuracy: 0.5876 - val_macro_f1: 0.7048
Epoch 11/23
311/311 - 191s - loss: 0.6619 - accuracy: 0.6163 - macro_f1: 0.6198 - val_loss: 0.6627 - val_accuracy: 0.6203 - val_macro_f1: 0.6172
Epoch 12/23
311/311 - 191s - loss: 0.6552 - accuracy: 0.6268 - macro_f1: 0.6336 - val_loss: 0.6578 - val_accuracy: 0.6239 - val_macro_f1: 0.6034
Epoch 13/23
311/311 - 191s - loss: 0.6525 - accuracy: 0.6278 - macro_f1: 0.6330 - val_loss: 0.6542 - val_accuracy: 0.6304 - val_macro_f1: 0.6271
Epoch 14/23
311/311 - 191s - loss: 0.6471 - accuracy: 0.6354 - macro_f1: 0.6421 - val_loss: 0.6668 - val_accuracy: 0.6161 - val_macro_f1: 0.6970
Epoch 15/23
311/311 - 191s - loss: 0.6464 - accuracy: 0.6374 - macro_f1: 0.6425 - val_loss: 0.6385 - val_accuracy: 0.6450 - val_macro_f1: 0.6713
Epoch 16/23
311/311 - 191s - loss: 0.6405 - accuracy: 0.6438 - macro_f1: 0.6502 - val_loss: 0.6416 - val_accuracy: 0.6412 - val_macro_f1: 0.6963
Epoch 17/23
311/311 - 191s - loss: 0.6347 - accuracy: 0.6500 - macro_f1: 0.6589 - val_loss: 0.6548 - val_accuracy: 0.6266 - val_macro_f1: 0.5697
Epoch 18/23
311/311 - 191s - loss: 0.6347 - accuracy: 0.6505 - macro_f1: 0.6577 - val_loss: 0.6432 - val_accuracy: 0.6423 - val_macro_f1: 0.6172
Epoch 19/23
311/311 - 191s - loss: 0.6313 - accuracy: 0.6539 - macro_f1: 0.6625 - val_loss: 0.6372 - val_accuracy: 0.6480 - val_macro_f1: 0.6420
Epoch 20/23
311/311 - 191s - loss: 0.6339 - accuracy: 0.6507 - macro_f1: 0.6559 - val_loss: 0.6505 - val_accuracy: 0.6334 - val_macro_f1: 0.5922
Epoch 21/23
311/311 - 191s - loss: 0.6252 - accuracy: 0.6604 - macro_f1: 0.6698 - val_loss: 0.6312 - val_accuracy: 0.6552 - val_macro_f1: 0.6794
Epoch 22/23
311/311 - 191s - loss: 0.6187 - accuracy: 0.6668 - macro_f1: 0.6779 - val_loss: 0.6582 - val_accuracy: 0.6221 - val_macro_f1: 0.5565
Epoch 23/23
311/311 - 191s - loss: 0.6194 - accuracy: 0.6664 - macro_f1: 0.6754 - val_loss: 0.6325 - val_accuracy: 0.6562 - val_macro_f1: 0.6823
Running cyclical learning rate for OPC_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.05.
In evaluation mode.
Traceback (most recent call last):
  File "train_singleTask_CNN_classifier_OCP.py", line 274, in <module>
    main(args)
  File "train_singleTask_CNN_classifier_OCP.py", line 197, in main
    (x_valid, y_valid, ids_valid) = encode_sequence2(args.valid_fasta_pos, args.valid_fasta_neg, size = args.seq_length, shuffleOff = True)
TypeError: encode_sequence2() got an unexpected keyword argument 'size'
Running cyclical learning rate for OPC_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.1.
In training mode.
There 164974 positives and 145248 negatives.
There 22612 positives and 20082 negatives.
Epoch 1/23
311/311 - 192s - loss: 0.6946 - accuracy: 0.5384 - macro_f1: 0.4844 - val_loss: 0.6898 - val_accuracy: 0.5572 - val_macro_f1: 0.4552
Epoch 2/23
311/311 - 191s - loss: 0.6841 - accuracy: 0.5699 - macro_f1: 0.5472 - val_loss: 0.6781 - val_accuracy: 0.5921 - val_macro_f1: 0.6569
Epoch 3/23
311/311 - 191s - loss: 0.6800 - accuracy: 0.5834 - macro_f1: 0.5760 - val_loss: 0.6741 - val_accuracy: 0.6041 - val_macro_f1: 0.6506
Epoch 4/23
311/311 - 191s - loss: 0.6773 - accuracy: 0.5889 - macro_f1: 0.5873 - val_loss: 0.6885 - val_accuracy: 0.5874 - val_macro_f1: 0.6044
Epoch 5/23
311/311 - 191s - loss: 0.6755 - accuracy: 0.5925 - macro_f1: 0.5858 - val_loss: 0.6703 - val_accuracy: 0.6094 - val_macro_f1: 0.6709
Epoch 6/23
311/311 - 191s - loss: 0.6699 - accuracy: 0.6038 - macro_f1: 0.6046 - val_loss: 0.6718 - val_accuracy: 0.6006 - val_macro_f1: 0.5507
Epoch 7/23
311/311 - 191s - loss: 0.6688 - accuracy: 0.6050 - macro_f1: 0.6059 - val_loss: 0.6839 - val_accuracy: 0.5735 - val_macro_f1: 0.4481
Epoch 8/23
311/311 - 191s - loss: 0.6671 - accuracy: 0.6091 - macro_f1: 0.6107 - val_loss: 0.6585 - val_accuracy: 0.6255 - val_macro_f1: 0.6527
Epoch 9/23
311/311 - 191s - loss: 0.6634 - accuracy: 0.6157 - macro_f1: 0.6191 - val_loss: 0.6669 - val_accuracy: 0.6070 - val_macro_f1: 0.7012
Epoch 10/23
311/311 - 191s - loss: 0.6618 - accuracy: 0.6174 - macro_f1: 0.6214 - val_loss: 0.6629 - val_accuracy: 0.6178 - val_macro_f1: 0.5859
Epoch 11/23
311/311 - 191s - loss: 0.6569 - accuracy: 0.6232 - macro_f1: 0.6280 - val_loss: 0.6493 - val_accuracy: 0.6357 - val_macro_f1: 0.6561
Epoch 12/23
311/311 - 191s - loss: 0.6544 - accuracy: 0.6263 - macro_f1: 0.6308 - val_loss: 0.6471 - val_accuracy: 0.6378 - val_macro_f1: 0.6532
Epoch 13/23
311/311 - 191s - loss: 0.6496 - accuracy: 0.6326 - macro_f1: 0.6387 - val_loss: 0.6852 - val_accuracy: 0.5868 - val_macro_f1: 0.4572
Epoch 14/23
311/311 - 191s - loss: 0.6486 - accuracy: 0.6338 - macro_f1: 0.6385 - val_loss: 0.6417 - val_accuracy: 0.6454 - val_macro_f1: 0.6626
Epoch 15/23
311/311 - 191s - loss: 0.6423 - accuracy: 0.6416 - macro_f1: 0.6493 - val_loss: 0.6443 - val_accuracy: 0.6419 - val_macro_f1: 0.6915
Epoch 16/23
311/311 - 191s - loss: 0.6437 - accuracy: 0.6401 - macro_f1: 0.6452 - val_loss: 0.6489 - val_accuracy: 0.6354 - val_macro_f1: 0.6164
Epoch 17/23
311/311 - 191s - loss: 0.6413 - accuracy: 0.6415 - macro_f1: 0.6456 - val_loss: 0.6369 - val_accuracy: 0.6500 - val_macro_f1: 0.6595
Epoch 18/23
311/311 - 191s - loss: 0.6329 - accuracy: 0.6517 - macro_f1: 0.6617 - val_loss: 0.6351 - val_accuracy: 0.6494 - val_macro_f1: 0.6971
Epoch 19/23
311/311 - 191s - loss: 0.6295 - accuracy: 0.6552 - macro_f1: 0.6663 - val_loss: 0.6337 - val_accuracy: 0.6538 - val_macro_f1: 0.6771
Epoch 20/23
311/311 - 191s - loss: 0.6282 - accuracy: 0.6571 - macro_f1: 0.6675 - val_loss: 0.6351 - val_accuracy: 0.6511 - val_macro_f1: 0.7047
Epoch 21/23
311/311 - 191s - loss: 0.6289 - accuracy: 0.6564 - macro_f1: 0.6639 - val_loss: 0.6388 - val_accuracy: 0.6474 - val_macro_f1: 0.6424
Epoch 22/23
311/311 - 191s - loss: 0.6217 - accuracy: 0.6641 - macro_f1: 0.6756 - val_loss: 0.6361 - val_accuracy: 0.6474 - val_macro_f1: 0.6330
Epoch 23/23
311/311 - 191s - loss: 0.6220 - accuracy: 0.6632 - macro_f1: 0.6713 - val_loss: 0.6494 - val_accuracy: 0.6367 - val_macro_f1: 0.5974
Running cyclical learning rate for OPC_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.1.
In evaluation mode.
Traceback (most recent call last):
  File "train_singleTask_CNN_classifier_OCP.py", line 274, in <module>
    main(args)
  File "train_singleTask_CNN_classifier_OCP.py", line 197, in main
    (x_valid, y_valid, ids_valid) = encode_sequence2(args.valid_fasta_pos, args.valid_fasta_neg, size = args.seq_length, shuffleOff = True)
TypeError: encode_sequence2() got an unexpected keyword argument 'size'
Running cyclical learning rate for OPC_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.15.
In training mode.
There 164974 positives and 145248 negatives.
There 22612 positives and 20082 negatives.
Epoch 1/23
311/311 - 192s - loss: 0.6958 - accuracy: 0.5354 - macro_f1: 0.4848 - val_loss: 0.6908 - val_accuracy: 0.5559 - val_macro_f1: 0.4716
Epoch 2/23
311/311 - 191s - loss: 0.6867 - accuracy: 0.5649 - macro_f1: 0.5399 - val_loss: 0.6960 - val_accuracy: 0.5444 - val_macro_f1: 0.3831
Epoch 3/23
311/311 - 191s - loss: 0.6814 - accuracy: 0.5784 - macro_f1: 0.5659 - val_loss: 0.6754 - val_accuracy: 0.5947 - val_macro_f1: 0.6707
Epoch 4/23
311/311 - 191s - loss: 0.6777 - accuracy: 0.5882 - macro_f1: 0.5827 - val_loss: 0.6741 - val_accuracy: 0.6051 - val_macro_f1: 0.6287
Epoch 5/23
311/311 - 191s - loss: 0.6760 - accuracy: 0.5928 - macro_f1: 0.5897 - val_loss: 0.6796 - val_accuracy: 0.5874 - val_macro_f1: 0.5212
Epoch 6/23
311/311 - 191s - loss: 0.6732 - accuracy: 0.5970 - macro_f1: 0.5933 - val_loss: 0.6729 - val_accuracy: 0.6013 - val_macro_f1: 0.5671
Epoch 7/23
311/311 - 191s - loss: 0.6695 - accuracy: 0.6048 - macro_f1: 0.6078 - val_loss: 0.6618 - val_accuracy: 0.6184 - val_macro_f1: 0.6706
Epoch 8/23
311/311 - 190s - loss: 0.6680 - accuracy: 0.6075 - macro_f1: 0.6080 - val_loss: 0.6670 - val_accuracy: 0.6186 - val_macro_f1: 0.6294
Epoch 9/23
311/311 - 190s - loss: 0.6672 - accuracy: 0.6085 - macro_f1: 0.6079 - val_loss: 0.6661 - val_accuracy: 0.6200 - val_macro_f1: 0.6736
Epoch 10/23
311/311 - 190s - loss: 0.6629 - accuracy: 0.6154 - macro_f1: 0.6179 - val_loss: 0.6686 - val_accuracy: 0.6103 - val_macro_f1: 0.7022
Epoch 11/23
311/311 - 190s - loss: 0.6604 - accuracy: 0.6200 - macro_f1: 0.6233 - val_loss: 0.6632 - val_accuracy: 0.6195 - val_macro_f1: 0.5899
Epoch 12/23
311/311 - 191s - loss: 0.6539 - accuracy: 0.6268 - macro_f1: 0.6328 - val_loss: 0.6558 - val_accuracy: 0.6277 - val_macro_f1: 0.6077
Epoch 13/23
311/311 - 191s - loss: 0.6514 - accuracy: 0.6297 - macro_f1: 0.6339 - val_loss: 0.6731 - val_accuracy: 0.5935 - val_macro_f1: 0.4890
Epoch 14/23
311/311 - 191s - loss: 0.6481 - accuracy: 0.6338 - macro_f1: 0.6386 - val_loss: 0.6456 - val_accuracy: 0.6429 - val_macro_f1: 0.6741
Epoch 15/23
311/311 - 190s - loss: 0.6474 - accuracy: 0.6349 - macro_f1: 0.6388 - val_loss: 0.6646 - val_accuracy: 0.6098 - val_macro_f1: 0.5318
Epoch 16/23
311/311 - 191s - loss: 0.6420 - accuracy: 0.6416 - macro_f1: 0.6487 - val_loss: 0.6467 - val_accuracy: 0.6373 - val_macro_f1: 0.6267
Epoch 17/23
311/311 - 190s - loss: 0.6408 - accuracy: 0.6428 - macro_f1: 0.6493 - val_loss: 0.6510 - val_accuracy: 0.6319 - val_macro_f1: 0.5928
Epoch 18/23
311/311 - 190s - loss: 0.6388 - accuracy: 0.6448 - macro_f1: 0.6517 - val_loss: 0.6417 - val_accuracy: 0.6418 - val_macro_f1: 0.6313
Epoch 19/23
311/311 - 190s - loss: 0.6389 - accuracy: 0.6448 - macro_f1: 0.6509 - val_loss: 0.6607 - val_accuracy: 0.6169 - val_macro_f1: 0.5405
Epoch 20/23
311/311 - 190s - loss: 0.6496 - accuracy: 0.6319 - macro_f1: 0.6309 - val_loss: 0.6394 - val_accuracy: 0.6473 - val_macro_f1: 0.6911
Epoch 21/23
311/311 - 190s - loss: 0.6357 - accuracy: 0.6488 - macro_f1: 0.6574 - val_loss: 0.6349 - val_accuracy: 0.6495 - val_macro_f1: 0.6582
Epoch 22/23
311/311 - 190s - loss: 0.6289 - accuracy: 0.6572 - macro_f1: 0.6689 - val_loss: 0.6318 - val_accuracy: 0.6554 - val_macro_f1: 0.6817
Epoch 23/23
311/311 - 190s - loss: 0.6264 - accuracy: 0.6587 - macro_f1: 0.6687 - val_loss: 0.6306 - val_accuracy: 0.6544 - val_macro_f1: 0.6686
Running cyclical learning rate for OPC_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.15.
In evaluation mode.
Traceback (most recent call last):
  File "train_singleTask_CNN_classifier_OCP.py", line 274, in <module>
    main(args)
  File "train_singleTask_CNN_classifier_OCP.py", line 197, in main
    (x_valid, y_valid, ids_valid) = encode_sequence2(args.valid_fasta_pos, args.valid_fasta_neg, size = args.seq_length, shuffleOff = True)
TypeError: encode_sequence2() got an unexpected keyword argument 'size'
Running cyclical learning rate for OPC_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.2.
In training mode.
There 164974 positives and 145248 negatives.
There 22612 positives and 20082 negatives.
Epoch 1/23
311/311 - 192s - loss: 0.6977 - accuracy: 0.5302 - macro_f1: 0.4755 - val_loss: 0.6888 - val_accuracy: 0.5624 - val_macro_f1: 0.5241
Epoch 2/23
311/311 - 191s - loss: 0.6853 - accuracy: 0.5677 - macro_f1: 0.5458 - val_loss: 0.6903 - val_accuracy: 0.5649 - val_macro_f1: 0.4660
Epoch 3/23
311/311 - 191s - loss: 0.6806 - accuracy: 0.5809 - macro_f1: 0.5719 - val_loss: 0.6790 - val_accuracy: 0.5912 - val_macro_f1: 0.5700
Epoch 4/23
311/311 - 191s - loss: 0.6793 - accuracy: 0.5850 - macro_f1: 0.5795 - val_loss: 0.6719 - val_accuracy: 0.6045 - val_macro_f1: 0.6514
Epoch 5/23
311/311 - 190s - loss: 0.6767 - accuracy: 0.5906 - macro_f1: 0.5851 - val_loss: 0.6787 - val_accuracy: 0.5883 - val_macro_f1: 0.5284
Epoch 6/23
311/311 - 190s - loss: 0.6709 - accuracy: 0.6018 - macro_f1: 0.6012 - val_loss: 0.6727 - val_accuracy: 0.6104 - val_macro_f1: 0.5993
Epoch 7/23
311/311 - 190s - loss: 0.6705 - accuracy: 0.6031 - macro_f1: 0.6036 - val_loss: 0.6680 - val_accuracy: 0.6068 - val_macro_f1: 0.6956
Epoch 8/23
311/311 - 190s - loss: 0.6676 - accuracy: 0.6080 - macro_f1: 0.6107 - val_loss: 0.6653 - val_accuracy: 0.6180 - val_macro_f1: 0.6369
Epoch 9/23
311/311 - 190s - loss: 0.6671 - accuracy: 0.6097 - macro_f1: 0.6113 - val_loss: 0.6655 - val_accuracy: 0.6173 - val_macro_f1: 0.6187
Epoch 10/23
311/311 - 190s - loss: 0.6657 - accuracy: 0.6106 - macro_f1: 0.6120 - val_loss: 0.6671 - val_accuracy: 0.6064 - val_macro_f1: 0.7013
Epoch 11/23
311/311 - 190s - loss: 0.6648 - accuracy: 0.6112 - macro_f1: 0.6141 - val_loss: 0.6574 - val_accuracy: 0.6268 - val_macro_f1: 0.6409
Epoch 12/23
311/311 - 190s - loss: 0.6603 - accuracy: 0.6196 - macro_f1: 0.6243 - val_loss: 0.7280 - val_accuracy: 0.5298 - val_macro_f1: 0.2583
Epoch 13/23
311/311 - 190s - loss: 0.6580 - accuracy: 0.6209 - macro_f1: 0.6256 - val_loss: 0.6536 - val_accuracy: 0.6336 - val_macro_f1: 0.6821
Epoch 14/23
311/311 - 190s - loss: 0.6548 - accuracy: 0.6259 - macro_f1: 0.6302 - val_loss: 0.6497 - val_accuracy: 0.6347 - val_macro_f1: 0.6899
Epoch 15/23
311/311 - 190s - loss: 0.6512 - accuracy: 0.6301 - macro_f1: 0.6355 - val_loss: 0.6499 - val_accuracy: 0.6372 - val_macro_f1: 0.6381
Epoch 16/23
311/311 - 190s - loss: 0.6477 - accuracy: 0.6355 - macro_f1: 0.6422 - val_loss: 0.6506 - val_accuracy: 0.6307 - val_macro_f1: 0.7070
Epoch 17/23
311/311 - 190s - loss: 0.6455 - accuracy: 0.6372 - macro_f1: 0.6446 - val_loss: 0.6397 - val_accuracy: 0.6448 - val_macro_f1: 0.6614
Epoch 18/23
311/311 - 190s - loss: 0.6433 - accuracy: 0.6400 - macro_f1: 0.6476 - val_loss: 0.6436 - val_accuracy: 0.6409 - val_macro_f1: 0.6390
Epoch 19/23
311/311 - 190s - loss: 0.6421 - accuracy: 0.6413 - macro_f1: 0.6483 - val_loss: 0.6584 - val_accuracy: 0.6189 - val_macro_f1: 0.5548
Epoch 20/23
311/311 - 190s - loss: 0.6451 - accuracy: 0.6365 - macro_f1: 0.6408 - val_loss: 0.6399 - val_accuracy: 0.6469 - val_macro_f1: 0.6778
Epoch 21/23
311/311 - 190s - loss: 0.6410 - accuracy: 0.6426 - macro_f1: 0.6490 - val_loss: 0.6381 - val_accuracy: 0.6463 - val_macro_f1: 0.6490
Epoch 22/23
311/311 - 190s - loss: 0.6391 - accuracy: 0.6443 - macro_f1: 0.6493 - val_loss: 0.6344 - val_accuracy: 0.6504 - val_macro_f1: 0.6878
Epoch 23/23
311/311 - 190s - loss: 0.6352 - accuracy: 0.6488 - macro_f1: 0.6573 - val_loss: 0.6318 - val_accuracy: 0.6529 - val_macro_f1: 0.6746
  File "train_singleTask_CNN_classifier_OCP.py", line 225
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 225
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 225
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 225
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 225
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
