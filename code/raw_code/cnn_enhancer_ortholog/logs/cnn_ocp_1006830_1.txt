Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.001 - 0.01.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.05.
In training mode.
There 380766 positives and 283508 negatives.
There 48948 positives and 35420 negatives.
Epoch 1/23
665/665 - 523s - loss: 0.6985 - accuracy: 0.5388 - macro_f1: 0.5395 - val_loss: 0.6770 - val_accuracy: 0.5982 - val_macro_f1: 0.6740
Epoch 2/23
665/665 - 525s - loss: 0.6783 - accuracy: 0.5918 - macro_f1: 0.6383 - val_loss: 0.6550 - val_accuracy: 0.6363 - val_macro_f1: 0.7222
Epoch 3/23
665/665 - 528s - loss: 0.6608 - accuracy: 0.6180 - macro_f1: 0.6523 - val_loss: 0.6624 - val_accuracy: 0.6145 - val_macro_f1: 0.6298
Epoch 4/23
665/665 - 529s - loss: 0.6507 - accuracy: 0.6314 - macro_f1: 0.6629 - val_loss: 0.6506 - val_accuracy: 0.6322 - val_macro_f1: 0.6512
Epoch 5/23
665/665 - 528s - loss: 0.6394 - accuracy: 0.6455 - macro_f1: 0.6767 - val_loss: 0.6197 - val_accuracy: 0.6730 - val_macro_f1: 0.7424
Epoch 6/23
665/665 - 527s - loss: 0.6296 - accuracy: 0.6571 - macro_f1: 0.6878 - val_loss: 0.6053 - val_accuracy: 0.6848 - val_macro_f1: 0.7523
Epoch 7/23
665/665 - 528s - loss: 0.6197 - accuracy: 0.6679 - macro_f1: 0.6986 - val_loss: 0.6414 - val_accuracy: 0.6440 - val_macro_f1: 0.6375
Epoch 8/23
665/665 - 529s - loss: 0.6091 - accuracy: 0.6782 - macro_f1: 0.7087 - val_loss: 0.5951 - val_accuracy: 0.6930 - val_macro_f1: 0.7313
Epoch 9/23
665/665 - 530s - loss: 0.6030 - accuracy: 0.6844 - macro_f1: 0.7149 - val_loss: 0.6607 - val_accuracy: 0.6294 - val_macro_f1: 0.5952
Epoch 10/23
665/665 - 531s - loss: 0.5963 - accuracy: 0.6908 - macro_f1: 0.7212 - val_loss: 0.6265 - val_accuracy: 0.6609 - val_macro_f1: 0.6557
Epoch 11/23
665/665 - 530s - loss: 0.5899 - accuracy: 0.6968 - macro_f1: 0.7271 - val_loss: 0.5699 - val_accuracy: 0.7170 - val_macro_f1: 0.7687
Epoch 12/23
665/665 - 530s - loss: 0.5838 - accuracy: 0.7025 - macro_f1: 0.7325 - val_loss: 0.5702 - val_accuracy: 0.7176 - val_macro_f1: 0.7634
Epoch 13/23
665/665 - 530s - loss: 0.5797 - accuracy: 0.7062 - macro_f1: 0.7358 - val_loss: 0.5635 - val_accuracy: 0.7214 - val_macro_f1: 0.7672
Epoch 14/23
665/665 - 531s - loss: 0.5752 - accuracy: 0.7105 - macro_f1: 0.7398 - val_loss: 0.6032 - val_accuracy: 0.6828 - val_macro_f1: 0.6882
Epoch 15/23
665/665 - 531s - loss: 0.5706 - accuracy: 0.7144 - macro_f1: 0.7438 - val_loss: 0.5797 - val_accuracy: 0.7078 - val_macro_f1: 0.7283
Epoch 16/23
665/665 - 532s - loss: 0.5646 - accuracy: 0.7192 - macro_f1: 0.7487 - val_loss: 0.5546 - val_accuracy: 0.7289 - val_macro_f1: 0.7703
Epoch 17/23
665/665 - 531s - loss: 0.5609 - accuracy: 0.7225 - macro_f1: 0.7517 - val_loss: 0.5794 - val_accuracy: 0.7059 - val_macro_f1: 0.7222
Epoch 18/23
665/665 - 531s - loss: 0.5585 - accuracy: 0.7245 - macro_f1: 0.7534 - val_loss: 0.6068 - val_accuracy: 0.6820 - val_macro_f1: 0.6802
Epoch 19/23
665/665 - 531s - loss: 0.5521 - accuracy: 0.7296 - macro_f1: 0.7587 - val_loss: 0.5611 - val_accuracy: 0.7248 - val_macro_f1: 0.7518
Epoch 20/23
665/665 - 531s - loss: 0.5531 - accuracy: 0.7288 - macro_f1: 0.7572 - val_loss: 0.5531 - val_accuracy: 0.7288 - val_macro_f1: 0.7616
Epoch 21/23
665/665 - 531s - loss: 0.5448 - accuracy: 0.7358 - macro_f1: 0.7645 - val_loss: 0.5465 - val_accuracy: 0.7358 - val_macro_f1: 0.7760
Epoch 22/23
665/665 - 531s - loss: 0.5396 - accuracy: 0.7397 - macro_f1: 0.7684 - val_loss: 0.5689 - val_accuracy: 0.7153 - val_macro_f1: 0.7343
Epoch 23/23
665/665 - 532s - loss: 0.5354 - accuracy: 0.7426 - macro_f1: 0.7709 - val_loss: 0.5443 - val_accuracy: 0.7360 - val_macro_f1: 0.7721
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.001 - 0.01.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.05.
In evaluation mode.
Traceback (most recent call last):
  File "train_singleTask_CNN_classifier_OCP.py", line 274, in <module>
    main(args)
  File "train_singleTask_CNN_classifier_OCP.py", line 197, in main
    (x_valid, y_valid, ids_valid) = encode_sequence2(args.valid_fasta_pos, args.valid_fasta_neg, size = args.seq_length, shuffleOff = True)
TypeError: encode_sequence2() got an unexpected keyword argument 'size'
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.001 - 0.01.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.1.
In training mode.
There 380766 positives and 283508 negatives.
There 48948 positives and 35420 negatives.
Epoch 1/23
665/665 - 522s - loss: 0.6993 - accuracy: 0.5359 - macro_f1: 0.5413 - val_loss: 0.6919 - val_accuracy: 0.5656 - val_macro_f1: 0.5901
Epoch 2/23
665/665 - 522s - loss: 0.6801 - accuracy: 0.5919 - macro_f1: 0.6475 - val_loss: 0.6795 - val_accuracy: 0.5890 - val_macro_f1: 0.6195
Epoch 3/23
665/665 - 522s - loss: 0.6639 - accuracy: 0.6146 - macro_f1: 0.6534 - val_loss: 0.6641 - val_accuracy: 0.6144 - val_macro_f1: 0.6316
Epoch 4/23
665/665 - 522s - loss: 0.6523 - accuracy: 0.6305 - macro_f1: 0.6651 - val_loss: 0.6347 - val_accuracy: 0.6566 - val_macro_f1: 0.7221
Epoch 5/23
665/665 - 522s - loss: 0.6428 - accuracy: 0.6428 - macro_f1: 0.6761 - val_loss: 0.6692 - val_accuracy: 0.6063 - val_macro_f1: 0.5865
Epoch 6/23
665/665 - 521s - loss: 0.6331 - accuracy: 0.6537 - macro_f1: 0.6863 - val_loss: 0.6342 - val_accuracy: 0.6532 - val_macro_f1: 0.6774
Epoch 7/23
665/665 - 521s - loss: 0.6268 - accuracy: 0.6605 - macro_f1: 0.6917 - val_loss: 0.6059 - val_accuracy: 0.6855 - val_macro_f1: 0.7615
Epoch 8/23
665/665 - 521s - loss: 0.6181 - accuracy: 0.6698 - macro_f1: 0.7005 - val_loss: 0.6094 - val_accuracy: 0.6791 - val_macro_f1: 0.7690
Epoch 9/23
665/665 - 525s - loss: 0.6125 - accuracy: 0.6757 - macro_f1: 0.7058 - val_loss: 0.6002 - val_accuracy: 0.6891 - val_macro_f1: 0.7251
Epoch 10/23
665/665 - 527s - loss: 0.6042 - accuracy: 0.6835 - macro_f1: 0.7135 - val_loss: 0.6219 - val_accuracy: 0.6648 - val_macro_f1: 0.6679
Epoch 11/23
665/665 - 527s - loss: 0.5996 - accuracy: 0.6880 - macro_f1: 0.7179 - val_loss: 0.5846 - val_accuracy: 0.7072 - val_macro_f1: 0.7480
Epoch 12/23
665/665 - 527s - loss: 0.5920 - accuracy: 0.6954 - macro_f1: 0.7257 - val_loss: 0.6351 - val_accuracy: 0.6497 - val_macro_f1: 0.6280
Epoch 13/23
665/665 - 528s - loss: 0.5873 - accuracy: 0.6996 - macro_f1: 0.7298 - val_loss: 0.6173 - val_accuracy: 0.6693 - val_macro_f1: 0.6652
Epoch 14/23
665/665 - 529s - loss: 0.5826 - accuracy: 0.7039 - macro_f1: 0.7340 - val_loss: 0.5708 - val_accuracy: 0.7176 - val_macro_f1: 0.7542
Epoch 15/23
665/665 - 530s - loss: 0.5768 - accuracy: 0.7091 - macro_f1: 0.7393 - val_loss: 0.6501 - val_accuracy: 0.6415 - val_macro_f1: 0.6051
Epoch 16/23
665/665 - 530s - loss: 0.5723 - accuracy: 0.7136 - macro_f1: 0.7440 - val_loss: 0.5613 - val_accuracy: 0.7245 - val_macro_f1: 0.7603
Epoch 17/23
665/665 - 531s - loss: 0.5690 - accuracy: 0.7159 - macro_f1: 0.7460 - val_loss: 0.5690 - val_accuracy: 0.7193 - val_macro_f1: 0.7473
Epoch 18/23
665/665 - 531s - loss: 0.5655 - accuracy: 0.7192 - macro_f1: 0.7491 - val_loss: 0.5812 - val_accuracy: 0.7056 - val_macro_f1: 0.7202
Epoch 19/23
665/665 - 533s - loss: 0.5608 - accuracy: 0.7230 - macro_f1: 0.7532 - val_loss: 0.5602 - val_accuracy: 0.7251 - val_macro_f1: 0.7543
Epoch 20/23
665/665 - 531s - loss: 0.5643 - accuracy: 0.7203 - macro_f1: 0.7492 - val_loss: 0.6035 - val_accuracy: 0.6866 - val_macro_f1: 0.6849
Epoch 21/23
665/665 - 532s - loss: 0.5537 - accuracy: 0.7288 - macro_f1: 0.7587 - val_loss: 0.5493 - val_accuracy: 0.7325 - val_macro_f1: 0.7659
Epoch 22/23
665/665 - 532s - loss: 0.5590 - accuracy: 0.7246 - macro_f1: 0.7530 - val_loss: 0.5843 - val_accuracy: 0.7017 - val_macro_f1: 0.7142
Epoch 23/23
665/665 - 532s - loss: 0.5507 - accuracy: 0.7317 - macro_f1: 0.7607 - val_loss: 0.5815 - val_accuracy: 0.7055 - val_macro_f1: 0.7139
  File "train_singleTask_CNN_classifier_OCP.py", line 229
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 229
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 229
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 229
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 229
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 229
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 229
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 229
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 229
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
