Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.1 - 1.0.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.05.
In training mode.
There 380766 positives and 283508 negatives.
There 48948 positives and 35420 negatives.
Epoch 1/23
665/665 - 401s - loss: 0.6897 - accuracy: 0.5327 - macro_f1: 0.4683 - val_loss: 0.6989 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 2/23
665/665 - 398s - loss: 0.6937 - accuracy: 0.5000 - macro_f1: 0.3628 - val_loss: 0.6929 - val_accuracy: 0.5802 - val_macro_f1: 0.7345
Epoch 3/23
665/665 - 398s - loss: 0.6934 - accuracy: 0.4997 - macro_f1: 0.3566 - val_loss: 0.6956 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 4/23
665/665 - 398s - loss: 0.6937 - accuracy: 0.4998 - macro_f1: 0.3707 - val_loss: 0.6956 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 5/23
665/665 - 398s - loss: 0.6935 - accuracy: 0.5025 - macro_f1: 0.3718 - val_loss: 0.7049 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 6/23
665/665 - 398s - loss: 0.6936 - accuracy: 0.4991 - macro_f1: 0.3664 - val_loss: 0.7005 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 7/23
665/665 - 398s - loss: 0.6936 - accuracy: 0.4981 - macro_f1: 0.3560 - val_loss: 0.6840 - val_accuracy: 0.5802 - val_macro_f1: 0.7345
Epoch 8/23
665/665 - 398s - loss: 0.6938 - accuracy: 0.5010 - macro_f1: 0.3723 - val_loss: 0.6906 - val_accuracy: 0.5802 - val_macro_f1: 0.7345
Epoch 9/23
665/665 - 397s - loss: 0.6937 - accuracy: 0.4967 - macro_f1: 0.3504 - val_loss: 0.6874 - val_accuracy: 0.5802 - val_macro_f1: 0.7345
Epoch 10/23
665/665 - 397s - loss: 0.6935 - accuracy: 0.4973 - macro_f1: 0.3506 - val_loss: 0.6947 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 11/23
665/665 - 397s - loss: 0.6937 - accuracy: 0.5019 - macro_f1: 0.3726 - val_loss: 0.6980 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 12/23
665/665 - 397s - loss: 0.6937 - accuracy: 0.4996 - macro_f1: 0.3616 - val_loss: 0.6921 - val_accuracy: 0.5802 - val_macro_f1: 0.7345
Epoch 13/23
665/665 - 397s - loss: 0.6935 - accuracy: 0.5020 - macro_f1: 0.3737 - val_loss: 0.6898 - val_accuracy: 0.5802 - val_macro_f1: 0.7345
Epoch 14/23
665/665 - 397s - loss: 0.6935 - accuracy: 0.5006 - macro_f1: 0.3660 - val_loss: 0.6973 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 15/23
665/665 - 397s - loss: 0.6936 - accuracy: 0.4996 - macro_f1: 0.3656 - val_loss: 0.7005 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 16/23
665/665 - 397s - loss: 0.6934 - accuracy: 0.5005 - macro_f1: 0.3680 - val_loss: 0.6908 - val_accuracy: 0.5802 - val_macro_f1: 0.7345
Epoch 17/23
665/665 - 398s - loss: 0.6936 - accuracy: 0.4977 - macro_f1: 0.3548 - val_loss: 0.6860 - val_accuracy: 0.5802 - val_macro_f1: 0.7345
Epoch 18/23
665/665 - 398s - loss: 0.6940 - accuracy: 0.5005 - macro_f1: 0.3661 - val_loss: 0.6899 - val_accuracy: 0.5802 - val_macro_f1: 0.7345
Epoch 19/23
665/665 - 398s - loss: 0.6937 - accuracy: 0.5016 - macro_f1: 0.3765 - val_loss: 0.7013 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 20/23
665/665 - 398s - loss: 0.6941 - accuracy: 0.4994 - macro_f1: 0.3555 - val_loss: 0.6844 - val_accuracy: 0.5802 - val_macro_f1: 0.7345
Epoch 21/23
665/665 - 398s - loss: 0.6936 - accuracy: 0.5022 - macro_f1: 0.3788 - val_loss: 0.6888 - val_accuracy: 0.5802 - val_macro_f1: 0.7345
Epoch 22/23
665/665 - 398s - loss: 0.6934 - accuracy: 0.5022 - macro_f1: 0.3758 - val_loss: 0.6918 - val_accuracy: 0.5802 - val_macro_f1: 0.7345
Epoch 23/23
665/665 - 398s - loss: 0.6936 - accuracy: 0.4989 - macro_f1: 0.3603 - val_loss: 0.6993 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.1 - 1.0.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.05.
In evaluation mode.
There 48948 positives and 35420 negatives.
85/85 - 10s
Accuracy: 0.5. 
f1_score: 0.24827674412671064.
roc_auc: 0.5.
prc_auc: 0.7900862886402428.
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.1 - 1.0.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.1.
In training mode.
There 380766 positives and 283508 negatives.
There 48948 positives and 35420 negatives.
Epoch 1/23
665/665 - 405s - loss: 0.6616 - accuracy: 0.5993 - macro_f1: 0.6167 - val_loss: 0.6280 - val_accuracy: 0.6596 - val_macro_f1: 0.7420
Epoch 2/23
665/665 - 404s - loss: 0.6200 - accuracy: 0.6579 - macro_f1: 0.6780 - val_loss: 0.5813 - val_accuracy: 0.7007 - val_macro_f1: 0.7603
Epoch 3/23
665/665 - 404s - loss: 0.6023 - accuracy: 0.6777 - macro_f1: 0.7017 - val_loss: 0.5601 - val_accuracy: 0.7175 - val_macro_f1: 0.7675
Epoch 4/23
665/665 - 404s - loss: 0.5921 - accuracy: 0.6882 - macro_f1: 0.7141 - val_loss: 0.5649 - val_accuracy: 0.7154 - val_macro_f1: 0.7545
Epoch 5/23
665/665 - 404s - loss: 0.5875 - accuracy: 0.6918 - macro_f1: 0.7151 - val_loss: 0.6112 - val_accuracy: 0.6571 - val_macro_f1: 0.6443
Epoch 6/23
665/665 - 399s - loss: nan - accuracy: 0.4941 - macro_f1: 0.2219 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 7/23
665/665 - 396s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 8/23
665/665 - 396s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 9/23
665/665 - 396s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 10/23
665/665 - 396s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 11/23
665/665 - 396s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 12/23
665/665 - 396s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 13/23
665/665 - 396s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 14/23
665/665 - 396s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 15/23
665/665 - 396s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 16/23
665/665 - 396s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 17/23
665/665 - 396s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 18/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 19/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 20/23
665/665 - 396s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 21/23
665/665 - 396s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 22/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 23/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.1 - 1.0.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.1.
In evaluation mode.
Traceback (most recent call last):
  File "train_singleTask_CNN_classifier_OCP.py", line 274, in <module>
    main(args)
  File "train_singleTask_CNN_classifier_OCP.py", line 197, in main
    (x_valid, y_valid, ids_valid) = encode_sequence2(args.valid_fasta_pos, args.valid_fasta_neg, size = args.seq_length, shuffleOff = True)
TypeError: encode_sequence2() got an unexpected keyword argument 'size'
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.1 - 1.0.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.15.
In training mode.
There 380766 positives and 283508 negatives.
There 48948 positives and 35420 negatives.
Epoch 1/23
665/665 - 405s - loss: 0.6761 - accuracy: 0.5717 - macro_f1: 0.5574 - val_loss: 0.6668 - val_accuracy: 0.6348 - val_macro_f1: 0.7127
Epoch 2/23
665/665 - 397s - loss: nan - accuracy: 0.4295 - macro_f1: 0.0131 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 3/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 4/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 5/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 6/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 7/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 8/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 9/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 10/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 11/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 12/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 13/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 14/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 15/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 16/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 17/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 18/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 19/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 20/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 21/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 22/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 23/23
665/665 - 397s - loss: nan - accuracy: 0.4268 - macro_f1: 0.0000e+00 - val_loss: nan - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.1 - 1.0.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.15.
In evaluation mode.
Traceback (most recent call last):
  File "train_singleTask_CNN_classifier_OCP.py", line 274, in <module>
    main(args)
  File "train_singleTask_CNN_classifier_OCP.py", line 197, in main
    (x_valid, y_valid, ids_valid) = encode_sequence2(args.valid_fasta_pos, args.valid_fasta_neg, size = args.seq_length, shuffleOff = True)
TypeError: encode_sequence2() got an unexpected keyword argument 'size'
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.1 - 1.0.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.2.
In training mode.
There 380766 positives and 283508 negatives.
There 48948 positives and 35420 negatives.
Epoch 1/23
665/665 - 402s - loss: 0.6877 - accuracy: 0.5247 - macro_f1: 0.4471 - val_loss: 0.6895 - val_accuracy: 0.5802 - val_macro_f1: 0.7343
Epoch 2/23
665/665 - 398s - loss: 0.6936 - accuracy: 0.5020 - macro_f1: 0.3747 - val_loss: 0.6855 - val_accuracy: 0.5802 - val_macro_f1: 0.7343
Epoch 3/23
665/665 - 398s - loss: 0.6937 - accuracy: 0.5036 - macro_f1: 0.3773 - val_loss: 0.7066 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 4/23
665/665 - 398s - loss: 0.6936 - accuracy: 0.4987 - macro_f1: 0.3583 - val_loss: 0.6859 - val_accuracy: 0.5802 - val_macro_f1: 0.7343
Epoch 5/23
665/665 - 398s - loss: 0.6938 - accuracy: 0.4998 - macro_f1: 0.3698 - val_loss: 0.6930 - val_accuracy: 0.5802 - val_macro_f1: 0.7343
Epoch 6/23
665/665 - 398s - loss: 0.6936 - accuracy: 0.4980 - macro_f1: 0.3550 - val_loss: 0.6923 - val_accuracy: 0.5802 - val_macro_f1: 0.7343
Epoch 7/23
665/665 - 398s - loss: 0.6935 - accuracy: 0.5022 - macro_f1: 0.3737 - val_loss: 0.6940 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 8/23
665/665 - 398s - loss: 0.6936 - accuracy: 0.5039 - macro_f1: 0.3825 - val_loss: 0.6886 - val_accuracy: 0.5802 - val_macro_f1: 0.7343
Epoch 9/23
665/665 - 398s - loss: 0.6936 - accuracy: 0.5043 - macro_f1: 0.3856 - val_loss: 0.6914 - val_accuracy: 0.5802 - val_macro_f1: 0.7343
Epoch 10/23
665/665 - 398s - loss: 0.6935 - accuracy: 0.5039 - macro_f1: 0.3784 - val_loss: 0.7023 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 11/23
665/665 - 398s - loss: 0.6937 - accuracy: 0.5024 - macro_f1: 0.3728 - val_loss: 0.7035 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 12/23
665/665 - 398s - loss: 0.6936 - accuracy: 0.4998 - macro_f1: 0.3677 - val_loss: 0.6914 - val_accuracy: 0.5802 - val_macro_f1: 0.7343
Epoch 13/23
665/665 - 398s - loss: 0.6935 - accuracy: 0.4963 - macro_f1: 0.3482 - val_loss: 0.6916 - val_accuracy: 0.5802 - val_macro_f1: 0.7343
Epoch 14/23
665/665 - 398s - loss: 0.6936 - accuracy: 0.5022 - macro_f1: 0.3737 - val_loss: 0.7011 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 15/23
665/665 - 398s - loss: 0.6937 - accuracy: 0.5017 - macro_f1: 0.3745 - val_loss: 0.6964 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 16/23
665/665 - 398s - loss: 0.6936 - accuracy: 0.4988 - macro_f1: 0.3563 - val_loss: 0.6851 - val_accuracy: 0.5802 - val_macro_f1: 0.7343
Epoch 17/23
665/665 - 398s - loss: 0.6936 - accuracy: 0.5014 - macro_f1: 0.3694 - val_loss: 0.6965 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 18/23
665/665 - 398s - loss: 0.6941 - accuracy: 0.4995 - macro_f1: 0.3645 - val_loss: 0.7039 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 19/23
665/665 - 398s - loss: 0.6935 - accuracy: 0.4990 - macro_f1: 0.3624 - val_loss: 0.6897 - val_accuracy: 0.5802 - val_macro_f1: 0.7343
Epoch 20/23
665/665 - 398s - loss: 0.6938 - accuracy: 0.4982 - macro_f1: 0.3540 - val_loss: 0.7002 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 21/23
665/665 - 398s - loss: 0.6938 - accuracy: 0.5001 - macro_f1: 0.3698 - val_loss: 0.6972 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 22/23
665/665 - 398s - loss: 0.6933 - accuracy: 0.4973 - macro_f1: 0.3476 - val_loss: 0.6940 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
Epoch 23/23
665/665 - 398s - loss: 0.6934 - accuracy: 0.4994 - macro_f1: 0.3635 - val_loss: 0.6950 - val_accuracy: 0.4198 - val_macro_f1: 0.0000e+00
  File "train_singleTask_CNN_classifier_OCP.py", line 228
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 228
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 228
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 228
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 228
    parser = argparse.ArgumentParser(description='Parse CNN parameters.')
         ^
IndentationError: expected an indented block
