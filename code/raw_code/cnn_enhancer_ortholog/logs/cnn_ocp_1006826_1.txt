Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.05.
In training mode.
Model exists w/o permission to overwrite. Use --force to overwrite.
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.05.
In evaluation mode.
There 48948 positives and 35420 negatives.
85/85 - 10s
Accuracy: 0.7142739604923964. 
f1_score: 0.7152419344672869.
roc_auc: 0.7879474686650492.
prc_auc: 0.8187601267902054.
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.1.
In training mode.
Model exists w/o permission to overwrite. Use --force to overwrite.
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.1.
In evaluation mode.
There 48948 positives and 35420 negatives.
85/85 - 10s
Accuracy: 0.7331675089853245. 
f1_score: 0.7398826217839204.
roc_auc: 0.8090664131774086.
prc_auc: 0.837097427292065.
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.15.
In training mode.
Model exists w/o permission to overwrite. Use --force to overwrite.
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.15.
In evaluation mode.
There 48948 positives and 35420 negatives.
85/85 - 10s
Accuracy: 0.7245739102841227. 
f1_score: 0.7088530626179443.
roc_auc: 0.8153109143655234.
prc_auc: 0.8445339890794055.
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.2.
In training mode.
Model exists w/o permission to overwrite. Use --force to overwrite.
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.2.
In evaluation mode.
There 48948 positives and 35420 negatives.
85/85 - 10s
Accuracy: 0.7481694836779736. 
f1_score: 0.7533787121874405.
roc_auc: 0.8240458697638633.
prc_auc: 0.8517760020216091.
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.25.
In training mode.
There 380766 positives and 283508 negatives.
There 48948 positives and 35420 negatives.
Epoch 1/23
665/665 - 415s - loss: 0.6858 - accuracy: 0.5676 - macro_f1: 0.5716 - val_loss: 0.6530 - val_accuracy: 0.6474 - val_macro_f1: 0.7247
Epoch 2/23
665/665 - 415s - loss: 0.6474 - accuracy: 0.6389 - macro_f1: 0.6716 - val_loss: 0.6750 - val_accuracy: 0.5823 - val_macro_f1: 0.5152
Epoch 3/23
665/665 - 414s - loss: 0.6178 - accuracy: 0.6715 - macro_f1: 0.7025 - val_loss: 0.6546 - val_accuracy: 0.6288 - val_macro_f1: 0.5920
Epoch 4/23
665/665 - 414s - loss: 0.5995 - accuracy: 0.6891 - macro_f1: 0.7193 - val_loss: 0.5763 - val_accuracy: 0.7169 - val_macro_f1: 0.7673
Epoch 5/23
665/665 - 413s - loss: 0.5891 - accuracy: 0.6988 - macro_f1: 0.7293 - val_loss: 0.5698 - val_accuracy: 0.7168 - val_macro_f1: 0.7730
Epoch 6/23
665/665 - 413s - loss: 0.5823 - accuracy: 0.7053 - macro_f1: 0.7351 - val_loss: 0.5642 - val_accuracy: 0.7216 - val_macro_f1: 0.7803
Epoch 7/23
665/665 - 414s - loss: 0.5765 - accuracy: 0.7100 - macro_f1: 0.7397 - val_loss: 0.5544 - val_accuracy: 0.7309 - val_macro_f1: 0.7782
Epoch 8/23
665/665 - 414s - loss: 0.5720 - accuracy: 0.7139 - macro_f1: 0.7431 - val_loss: 0.5612 - val_accuracy: 0.7221 - val_macro_f1: 0.7508
Epoch 9/23
665/665 - 413s - loss: 0.5700 - accuracy: 0.7153 - macro_f1: 0.7443 - val_loss: 0.6643 - val_accuracy: 0.6265 - val_macro_f1: 0.5682
Epoch 10/23
665/665 - 413s - loss: 0.5655 - accuracy: 0.7198 - macro_f1: 0.7487 - val_loss: 0.5870 - val_accuracy: 0.7005 - val_macro_f1: 0.7055
Epoch 11/23
665/665 - 413s - loss: 0.5618 - accuracy: 0.7226 - macro_f1: 0.7515 - val_loss: 0.5436 - val_accuracy: 0.7403 - val_macro_f1: 0.7810
Epoch 12/23
665/665 - 413s - loss: 0.5578 - accuracy: 0.7254 - macro_f1: 0.7541 - val_loss: 0.5446 - val_accuracy: 0.7381 - val_macro_f1: 0.7935
Epoch 13/23
665/665 - 413s - loss: 0.5533 - accuracy: 0.7289 - macro_f1: 0.7576 - val_loss: 0.5613 - val_accuracy: 0.7229 - val_macro_f1: 0.7410
Epoch 14/23
665/665 - 413s - loss: 0.5509 - accuracy: 0.7314 - macro_f1: 0.7596 - val_loss: 0.5442 - val_accuracy: 0.7391 - val_macro_f1: 0.7716
Epoch 15/23
665/665 - 413s - loss: 0.5455 - accuracy: 0.7356 - macro_f1: 0.7638 - val_loss: 0.5937 - val_accuracy: 0.6910 - val_macro_f1: 0.6851
Epoch 16/23
665/665 - 413s - loss: 0.5434 - accuracy: 0.7373 - macro_f1: 0.7656 - val_loss: 0.5389 - val_accuracy: 0.7423 - val_macro_f1: 0.7741
Epoch 17/23
665/665 - 413s - loss: 0.5403 - accuracy: 0.7395 - macro_f1: 0.7679 - val_loss: 0.5324 - val_accuracy: 0.7465 - val_macro_f1: 0.7823
Epoch 18/23
665/665 - 413s - loss: 0.5386 - accuracy: 0.7406 - macro_f1: 0.7689 - val_loss: 0.5242 - val_accuracy: 0.7501 - val_macro_f1: 0.7904
Epoch 19/23
665/665 - 413s - loss: 0.5389 - accuracy: 0.7406 - macro_f1: 0.7684 - val_loss: 0.5260 - val_accuracy: 0.7502 - val_macro_f1: 0.7869
Epoch 20/23
665/665 - 413s - loss: 0.5359 - accuracy: 0.7427 - macro_f1: 0.7706 - val_loss: 0.5376 - val_accuracy: 0.7443 - val_macro_f1: 0.7720
Epoch 21/23
665/665 - 413s - loss: 0.5319 - accuracy: 0.7462 - macro_f1: 0.7738 - val_loss: 0.5475 - val_accuracy: 0.7366 - val_macro_f1: 0.7578
Epoch 22/23
665/665 - 413s - loss: 0.5326 - accuracy: 0.7449 - macro_f1: 0.7722 - val_loss: 0.5385 - val_accuracy: 0.7422 - val_macro_f1: 0.7672
Epoch 23/23
665/665 - 413s - loss: 0.5266 - accuracy: 0.7488 - macro_f1: 0.7761 - val_loss: 0.5222 - val_accuracy: 0.7529 - val_macro_f1: 0.7989
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.25.
In evaluation mode.
Traceback (most recent call last):
  File "train_singleTask_CNN_classifier_OCP.py", line 274, in <module>
    main(args)
  File "train_singleTask_CNN_classifier_OCP.py", line 197, in main
    (x_valid, y_valid, ids_valid) = encode_sequence2(args.valid_fasta_pos, args.valid_fasta_neg, size = args.seq_length, shuffleOff = True)
TypeError: encode_sequence2() got an unexpected keyword argument 'size'
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.3.
In training mode.
There 380766 positives and 283508 negatives.
There 48948 positives and 35420 negatives.
Epoch 1/23
665/665 - 416s - loss: 0.6807 - accuracy: 0.5779 - macro_f1: 0.5977 - val_loss: 0.6737 - val_accuracy: 0.5966 - val_macro_f1: 0.5860
Epoch 2/23
665/665 - 416s - loss: 0.6453 - accuracy: 0.6402 - macro_f1: 0.6713 - val_loss: 0.6471 - val_accuracy: 0.6374 - val_macro_f1: 0.6391
Epoch 3/23
665/665 - 414s - loss: 0.6168 - accuracy: 0.6721 - macro_f1: 0.7026 - val_loss: 0.6286 - val_accuracy: 0.6566 - val_macro_f1: 0.6559
Epoch 4/23
665/665 - 413s - loss: 0.5991 - accuracy: 0.6906 - macro_f1: 0.7212 - val_loss: 0.6288 - val_accuracy: 0.6619 - val_macro_f1: 0.6539
Epoch 5/23
665/665 - 413s - loss: 0.5915 - accuracy: 0.6973 - macro_f1: 0.7271 - val_loss: 0.5851 - val_accuracy: 0.7040 - val_macro_f1: 0.7271
Epoch 6/23
665/665 - 413s - loss: 0.5834 - accuracy: 0.7041 - macro_f1: 0.7344 - val_loss: 0.5634 - val_accuracy: 0.7223 - val_macro_f1: 0.7606
Epoch 7/23
665/665 - 413s - loss: 0.5787 - accuracy: 0.7086 - macro_f1: 0.7381 - val_loss: 0.5576 - val_accuracy: 0.7288 - val_macro_f1: 0.7786
Epoch 8/23
665/665 - 413s - loss: 0.5737 - accuracy: 0.7122 - macro_f1: 0.7418 - val_loss: 0.5694 - val_accuracy: 0.7192 - val_macro_f1: 0.7436
Epoch 9/23
665/665 - 413s - loss: 0.5708 - accuracy: 0.7151 - macro_f1: 0.7440 - val_loss: 0.5708 - val_accuracy: 0.7099 - val_macro_f1: 0.7306
Epoch 10/23
665/665 - 413s - loss: 0.5674 - accuracy: 0.7179 - macro_f1: 0.7465 - val_loss: 0.6006 - val_accuracy: 0.6886 - val_macro_f1: 0.6860
Epoch 11/23
665/665 - 413s - loss: 0.5619 - accuracy: 0.7231 - macro_f1: 0.7519 - val_loss: 0.5961 - val_accuracy: 0.6898 - val_macro_f1: 0.6847
Epoch 12/23
665/665 - 413s - loss: 0.5588 - accuracy: 0.7251 - macro_f1: 0.7539 - val_loss: 0.6617 - val_accuracy: 0.6231 - val_macro_f1: 0.5579
Epoch 13/23
665/665 - 412s - loss: 0.5549 - accuracy: 0.7278 - macro_f1: 0.7564 - val_loss: 0.5474 - val_accuracy: 0.7348 - val_macro_f1: 0.7610
Epoch 14/23
665/665 - 413s - loss: 0.5512 - accuracy: 0.7308 - macro_f1: 0.7595 - val_loss: 0.5334 - val_accuracy: 0.7479 - val_macro_f1: 0.7884
Epoch 15/23
665/665 - 413s - loss: 0.5501 - accuracy: 0.7321 - macro_f1: 0.7605 - val_loss: 0.5494 - val_accuracy: 0.7350 - val_macro_f1: 0.7585
Epoch 16/23
665/665 - 413s - loss: 0.5465 - accuracy: 0.7346 - macro_f1: 0.7632 - val_loss: 0.5403 - val_accuracy: 0.7386 - val_macro_f1: 0.7666
Epoch 17/23
665/665 - 413s - loss: 0.5456 - accuracy: 0.7354 - macro_f1: 0.7638 - val_loss: 0.5450 - val_accuracy: 0.7383 - val_macro_f1: 0.7625
Epoch 18/23
665/665 - 413s - loss: 0.5426 - accuracy: 0.7383 - macro_f1: 0.7668 - val_loss: 0.5502 - val_accuracy: 0.7330 - val_macro_f1: 0.7542
Epoch 19/23
665/665 - 413s - loss: 0.5427 - accuracy: 0.7378 - macro_f1: 0.7659 - val_loss: 0.5380 - val_accuracy: 0.7434 - val_macro_f1: 0.7716
Epoch 20/23
665/665 - 412s - loss: 0.5398 - accuracy: 0.7397 - macro_f1: 0.7679 - val_loss: 0.5465 - val_accuracy: 0.7370 - val_macro_f1: 0.7610
Epoch 21/23
665/665 - 413s - loss: 0.5380 - accuracy: 0.7412 - macro_f1: 0.7696 - val_loss: 0.5432 - val_accuracy: 0.7410 - val_macro_f1: 0.7653
Epoch 22/23
665/665 - 412s - loss: 0.5342 - accuracy: 0.7440 - macro_f1: 0.7720 - val_loss: 0.5500 - val_accuracy: 0.7327 - val_macro_f1: 0.7505
Epoch 23/23
665/665 - 412s - loss: 0.5335 - accuracy: 0.7442 - macro_f1: 0.7718 - val_loss: 0.5347 - val_accuracy: 0.7458 - val_macro_f1: 0.7745
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.3.
In evaluation mode.
Traceback (most recent call last):
  File "train_singleTask_CNN_classifier_OCP.py", line 274, in <module>
    main(args)
  File "train_singleTask_CNN_classifier_OCP.py", line 197, in main
    (x_valid, y_valid, ids_valid) = encode_sequence2(args.valid_fasta_pos, args.valid_fasta_neg, size = args.seq_length, shuffleOff = True)
TypeError: encode_sequence2() got an unexpected keyword argument 'size'
