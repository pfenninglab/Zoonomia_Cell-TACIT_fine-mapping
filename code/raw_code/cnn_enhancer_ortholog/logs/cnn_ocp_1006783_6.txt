Running cyclical learning rate for Microglia_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.05.
In training mode.
There 171186 positives and 139774 negatives.
There 23044 positives and 18546 negatives.
Epoch 1/23
311/311 - 247s - loss: 0.6902 - accuracy: 0.5148 - macro_f1: 0.4368 - val_loss: 0.6827 - val_accuracy: 0.5583 - val_macro_f1: 0.6448
Epoch 2/23
311/311 - 245s - loss: 0.6829 - accuracy: 0.5482 - macro_f1: 0.5455 - val_loss: 0.6758 - val_accuracy: 0.5742 - val_macro_f1: 0.6523
Epoch 3/23
311/311 - 245s - loss: 0.6755 - accuracy: 0.5722 - macro_f1: 0.5724 - val_loss: 0.6561 - val_accuracy: 0.6095 - val_macro_f1: 0.6998
Epoch 4/23
311/311 - 244s - loss: 0.6532 - accuracy: 0.6128 - macro_f1: 0.6122 - val_loss: 0.6843 - val_accuracy: 0.5492 - val_macro_f1: 0.3986
Epoch 5/23
311/311 - 244s - loss: 0.6407 - accuracy: 0.6322 - macro_f1: 0.6364 - val_loss: 0.6227 - val_accuracy: 0.6565 - val_macro_f1: 0.6926
Epoch 6/23
311/311 - 245s - loss: 0.6303 - accuracy: 0.6455 - macro_f1: 0.6556 - val_loss: 0.6189 - val_accuracy: 0.6574 - val_macro_f1: 0.6980
Epoch 7/23
311/311 - 244s - loss: 0.6236 - accuracy: 0.6529 - macro_f1: 0.6642 - val_loss: 0.6371 - val_accuracy: 0.6346 - val_macro_f1: 0.6144
Epoch 8/23
311/311 - 245s - loss: 0.6211 - accuracy: 0.6561 - macro_f1: 0.6677 - val_loss: 0.6298 - val_accuracy: 0.6453 - val_macro_f1: 0.6425
Epoch 9/23
311/311 - 244s - loss: 0.6171 - accuracy: 0.6596 - macro_f1: 0.6718 - val_loss: 0.6237 - val_accuracy: 0.6539 - val_macro_f1: 0.6595
Epoch 10/23
311/311 - 245s - loss: 0.6156 - accuracy: 0.6613 - macro_f1: 0.6727 - val_loss: 0.6131 - val_accuracy: 0.6649 - val_macro_f1: 0.6964
Epoch 11/23
311/311 - 245s - loss: 0.6096 - accuracy: 0.6676 - macro_f1: 0.6819 - val_loss: 0.6124 - val_accuracy: 0.6666 - val_macro_f1: 0.7202
Epoch 12/23
311/311 - 245s - loss: 0.6065 - accuracy: 0.6696 - macro_f1: 0.6835 - val_loss: 0.6105 - val_accuracy: 0.6664 - val_macro_f1: 0.7020
Epoch 13/23
311/311 - 247s - loss: 0.6047 - accuracy: 0.6720 - macro_f1: 0.6850 - val_loss: 0.6111 - val_accuracy: 0.6655 - val_macro_f1: 0.6942
Epoch 14/23
311/311 - 248s - loss: 0.5980 - accuracy: 0.6785 - macro_f1: 0.6928 - val_loss: 0.6108 - val_accuracy: 0.6676 - val_macro_f1: 0.7089
Epoch 15/23
311/311 - 248s - loss: 0.5932 - accuracy: 0.6832 - macro_f1: 0.6984 - val_loss: 0.6163 - val_accuracy: 0.6625 - val_macro_f1: 0.6761
Epoch 16/23
311/311 - 248s - loss: 0.5888 - accuracy: 0.6873 - macro_f1: 0.7024 - val_loss: 0.6159 - val_accuracy: 0.6598 - val_macro_f1: 0.6770
Epoch 17/23
311/311 - 247s - loss: 0.5839 - accuracy: 0.6911 - macro_f1: 0.7055 - val_loss: 0.6131 - val_accuracy: 0.6689 - val_macro_f1: 0.7137
Epoch 18/23
311/311 - 247s - loss: 0.5782 - accuracy: 0.6954 - macro_f1: 0.7112 - val_loss: 0.6378 - val_accuracy: 0.6387 - val_macro_f1: 0.6210
Epoch 19/23
311/311 - 247s - loss: 0.5736 - accuracy: 0.6989 - macro_f1: 0.7136 - val_loss: 0.6291 - val_accuracy: 0.6494 - val_macro_f1: 0.6513
Epoch 20/23
311/311 - 247s - loss: 0.5713 - accuracy: 0.7012 - macro_f1: 0.7153 - val_loss: 0.6369 - val_accuracy: 0.6427 - val_macro_f1: 0.6355
Epoch 21/23
311/311 - 247s - loss: 0.5623 - accuracy: 0.7086 - macro_f1: 0.7222 - val_loss: 0.6295 - val_accuracy: 0.6612 - val_macro_f1: 0.6975
Epoch 22/23
311/311 - 247s - loss: 0.5500 - accuracy: 0.7183 - macro_f1: 0.7330 - val_loss: 0.6339 - val_accuracy: 0.6572 - val_macro_f1: 0.6929
Epoch 23/23
311/311 - 248s - loss: 0.5373 - accuracy: 0.7270 - macro_f1: 0.7414 - val_loss: 0.6412 - val_accuracy: 0.6476 - val_macro_f1: 0.6814
Running cyclical learning rate for Microglia_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.05.
In evaluation mode.
There 23044 positives and 18546 negatives.
42/42 - 8s
Accuracy: 0.6434199262424054. 
f1_score: 0.6475706071420468.
roc_auc: 0.6991917658055886.
prc_auc: 0.7286694214014737.
Running cyclical learning rate for Microglia_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.1.
In training mode.
There 171186 positives and 139774 negatives.
There 23044 positives and 18546 negatives.
Epoch 1/23
311/311 - 248s - loss: 0.6897 - accuracy: 0.5149 - macro_f1: 0.4454 - val_loss: 0.6823 - val_accuracy: 0.5587 - val_macro_f1: 0.6471
Epoch 2/23
311/311 - 246s - loss: 0.6836 - accuracy: 0.5449 - macro_f1: 0.5394 - val_loss: 0.6765 - val_accuracy: 0.5691 - val_macro_f1: 0.6468
Epoch 3/23
311/311 - 246s - loss: 0.6803 - accuracy: 0.5599 - macro_f1: 0.5628 - val_loss: 0.6742 - val_accuracy: 0.5801 - val_macro_f1: 0.6066
Epoch 4/23
311/311 - 247s - loss: 0.6737 - accuracy: 0.5772 - macro_f1: 0.5815 - val_loss: 0.6546 - val_accuracy: 0.6148 - val_macro_f1: 0.6433
Epoch 5/23
311/311 - 247s - loss: 0.6514 - accuracy: 0.6187 - macro_f1: 0.6223 - val_loss: 0.6313 - val_accuracy: 0.6462 - val_macro_f1: 0.6803
Epoch 6/23
311/311 - 248s - loss: 0.6384 - accuracy: 0.6370 - macro_f1: 0.6454 - val_loss: 0.6439 - val_accuracy: 0.6279 - val_macro_f1: 0.6080
Epoch 7/23
311/311 - 248s - loss: 0.6307 - accuracy: 0.6460 - macro_f1: 0.6568 - val_loss: 0.6258 - val_accuracy: 0.6491 - val_macro_f1: 0.6585
Epoch 8/23
311/311 - 248s - loss: 0.6270 - accuracy: 0.6505 - macro_f1: 0.6619 - val_loss: 0.6353 - val_accuracy: 0.6341 - val_macro_f1: 0.6165
Epoch 9/23
311/311 - 248s - loss: 0.6242 - accuracy: 0.6531 - macro_f1: 0.6644 - val_loss: 0.6355 - val_accuracy: 0.6356 - val_macro_f1: 0.6179
Epoch 10/23
311/311 - 248s - loss: 0.6227 - accuracy: 0.6540 - macro_f1: 0.6642 - val_loss: 0.6373 - val_accuracy: 0.6348 - val_macro_f1: 0.6148
Epoch 11/23
311/311 - 248s - loss: 0.6170 - accuracy: 0.6602 - macro_f1: 0.6734 - val_loss: 0.6307 - val_accuracy: 0.6430 - val_macro_f1: 0.6269
Epoch 12/23
311/311 - 249s - loss: 0.6161 - accuracy: 0.6610 - macro_f1: 0.6734 - val_loss: 0.6127 - val_accuracy: 0.6660 - val_macro_f1: 0.7172
Epoch 13/23
311/311 - 249s - loss: 0.6123 - accuracy: 0.6642 - macro_f1: 0.6771 - val_loss: 0.6238 - val_accuracy: 0.6514 - val_macro_f1: 0.6521
Epoch 14/23
311/311 - 248s - loss: 0.6090 - accuracy: 0.6678 - macro_f1: 0.6817 - val_loss: 0.6225 - val_accuracy: 0.6511 - val_macro_f1: 0.6478
Epoch 15/23
311/311 - 249s - loss: 0.6071 - accuracy: 0.6695 - macro_f1: 0.6828 - val_loss: 0.6127 - val_accuracy: 0.6645 - val_macro_f1: 0.6875
Epoch 16/23
311/311 - 249s - loss: 0.6037 - accuracy: 0.6731 - macro_f1: 0.6869 - val_loss: 0.6295 - val_accuracy: 0.6416 - val_macro_f1: 0.6238
Epoch 17/23
311/311 - 249s - loss: 0.5998 - accuracy: 0.6769 - macro_f1: 0.6911 - val_loss: 0.6316 - val_accuracy: 0.6400 - val_macro_f1: 0.6203
Epoch 18/23
311/311 - 249s - loss: 0.5958 - accuracy: 0.6805 - macro_f1: 0.6954 - val_loss: 0.6256 - val_accuracy: 0.6493 - val_macro_f1: 0.6397
Epoch 19/23
311/311 - 249s - loss: 0.5939 - accuracy: 0.6821 - macro_f1: 0.6958 - val_loss: 0.6085 - val_accuracy: 0.6723 - val_macro_f1: 0.7272
Epoch 20/23
311/311 - 249s - loss: 0.5942 - accuracy: 0.6814 - macro_f1: 0.6949 - val_loss: 0.6100 - val_accuracy: 0.6670 - val_macro_f1: 0.6908
Epoch 21/23
311/311 - 249s - loss: 0.5862 - accuracy: 0.6887 - macro_f1: 0.7035 - val_loss: 0.6115 - val_accuracy: 0.6630 - val_macro_f1: 0.6882
Epoch 22/23
311/311 - 249s - loss: 0.5803 - accuracy: 0.6941 - macro_f1: 0.7089 - val_loss: 0.6118 - val_accuracy: 0.6680 - val_macro_f1: 0.7002
Epoch 23/23
311/311 - 249s - loss: 0.5719 - accuracy: 0.7008 - macro_f1: 0.7167 - val_loss: 0.6263 - val_accuracy: 0.6510 - val_macro_f1: 0.6513
Running cyclical learning rate for Microglia_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.1.
In evaluation mode.
There 23044 positives and 18546 negatives.
42/42 - 8s
Accuracy: 0.6584853481876568. 
f1_score: 0.6511355168318063.
roc_auc: 0.7228822147599686.
prc_auc: 0.7493317998807987.
Running cyclical learning rate for Microglia_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.15.
In training mode.
There 171186 positives and 139774 negatives.
There 23044 positives and 18546 negatives.
Epoch 1/23
311/311 - 248s - loss: 0.6915 - accuracy: 0.5138 - macro_f1: 0.4599 - val_loss: 0.6917 - val_accuracy: 0.5041 - val_macro_f1: 0.3640
Epoch 2/23
311/311 - 245s - loss: 0.6851 - accuracy: 0.5373 - macro_f1: 0.5192 - val_loss: 0.6858 - val_accuracy: 0.5273 - val_macro_f1: 0.5011
Epoch 3/23
311/311 - 245s - loss: 0.6814 - accuracy: 0.5542 - macro_f1: 0.5564 - val_loss: 0.6942 - val_accuracy: 0.4860 - val_macro_f1: 0.2220
Epoch 4/23
311/311 - 245s - loss: 0.6724 - accuracy: 0.5787 - macro_f1: 0.5838 - val_loss: 0.6591 - val_accuracy: 0.6088 - val_macro_f1: 0.5972
Epoch 5/23
311/311 - 244s - loss: 0.6536 - accuracy: 0.6139 - macro_f1: 0.6150 - val_loss: 0.6427 - val_accuracy: 0.6275 - val_macro_f1: 0.6476
Epoch 6/23
311/311 - 244s - loss: 0.6381 - accuracy: 0.6361 - macro_f1: 0.6446 - val_loss: 0.6337 - val_accuracy: 0.6414 - val_macro_f1: 0.6431
Epoch 7/23
311/311 - 244s - loss: 0.6324 - accuracy: 0.6428 - macro_f1: 0.6514 - val_loss: 0.6282 - val_accuracy: 0.6500 - val_macro_f1: 0.7094
Epoch 8/23
311/311 - 244s - loss: 0.6292 - accuracy: 0.6466 - macro_f1: 0.6565 - val_loss: 0.6412 - val_accuracy: 0.6284 - val_macro_f1: 0.6006
Epoch 9/23
311/311 - 245s - loss: 0.6250 - accuracy: 0.6514 - macro_f1: 0.6616 - val_loss: 0.6394 - val_accuracy: 0.6325 - val_macro_f1: 0.6103
Epoch 10/23
311/311 - 246s - loss: 0.6239 - accuracy: 0.6527 - macro_f1: 0.6637 - val_loss: 0.6468 - val_accuracy: 0.6223 - val_macro_f1: 0.5798
Epoch 11/23
311/311 - 246s - loss: 0.6207 - accuracy: 0.6562 - macro_f1: 0.6679 - val_loss: 0.6215 - val_accuracy: 0.6532 - val_macro_f1: 0.6624
Epoch 12/23
311/311 - 246s - loss: 0.6179 - accuracy: 0.6593 - macro_f1: 0.6715 - val_loss: 0.6226 - val_accuracy: 0.6509 - val_macro_f1: 0.6584
Epoch 13/23
311/311 - 246s - loss: 0.6163 - accuracy: 0.6601 - macro_f1: 0.6725 - val_loss: 0.6204 - val_accuracy: 0.6554 - val_macro_f1: 0.6625
Epoch 14/23
311/311 - 247s - loss: 0.6127 - accuracy: 0.6647 - macro_f1: 0.6780 - val_loss: 0.6229 - val_accuracy: 0.6511 - val_macro_f1: 0.6489
Epoch 15/23
311/311 - 248s - loss: 0.6106 - accuracy: 0.6665 - macro_f1: 0.6795 - val_loss: 0.6203 - val_accuracy: 0.6568 - val_macro_f1: 0.6579
Epoch 16/23
311/311 - 247s - loss: 0.6078 - accuracy: 0.6694 - macro_f1: 0.6826 - val_loss: 0.6216 - val_accuracy: 0.6531 - val_macro_f1: 0.6494
Epoch 17/23
311/311 - 247s - loss: 0.6052 - accuracy: 0.6723 - macro_f1: 0.6862 - val_loss: 0.6076 - val_accuracy: 0.6716 - val_macro_f1: 0.7088
Epoch 18/23
311/311 - 248s - loss: 0.6041 - accuracy: 0.6728 - macro_f1: 0.6860 - val_loss: 0.6331 - val_accuracy: 0.6431 - val_macro_f1: 0.6226
Epoch 19/23
311/311 - 248s - loss: 0.6044 - accuracy: 0.6724 - macro_f1: 0.6851 - val_loss: 0.6221 - val_accuracy: 0.6523 - val_macro_f1: 0.6408
Epoch 20/23
311/311 - 248s - loss: 0.5964 - accuracy: 0.6809 - macro_f1: 0.6960 - val_loss: 0.6189 - val_accuracy: 0.6586 - val_macro_f1: 0.6607
Epoch 21/23
311/311 - 248s - loss: 0.5947 - accuracy: 0.6816 - macro_f1: 0.6958 - val_loss: 0.6245 - val_accuracy: 0.6486 - val_macro_f1: 0.6357
Epoch 22/23
311/311 - 248s - loss: 0.5869 - accuracy: 0.6895 - macro_f1: 0.7054 - val_loss: 0.6111 - val_accuracy: 0.6671 - val_macro_f1: 0.6858
Epoch 23/23
311/311 - 248s - loss: 0.5832 - accuracy: 0.6919 - macro_f1: 0.7079 - val_loss: 0.6270 - val_accuracy: 0.6471 - val_macro_f1: 0.6323
Running cyclical learning rate for Microglia_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.15.
In evaluation mode.
There 23044 positives and 18546 negatives.
42/42 - 8s
Accuracy: 0.6590947347796692. 
f1_score: 0.6450345875180347.
roc_auc: 0.7275218369378482.
prc_auc: 0.7551544654833774.
Running cyclical learning rate for Microglia_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.2.
In training mode.
There 171186 positives and 139774 negatives.
There 23044 positives and 18546 negatives.
Epoch 1/23
311/311 - 248s - loss: 0.6931 - accuracy: 0.5017 - macro_f1: 0.3940 - val_loss: 0.6876 - val_accuracy: 0.5541 - val_macro_f1: 0.7131
Epoch 2/23
311/311 - 246s - loss: 0.6875 - accuracy: 0.5320 - macro_f1: 0.5194 - val_loss: 0.6937 - val_accuracy: 0.4912 - val_macro_f1: 0.2657
Epoch 3/23
311/311 - 246s - loss: 0.6845 - accuracy: 0.5448 - macro_f1: 0.5449 - val_loss: 0.6816 - val_accuracy: 0.5486 - val_macro_f1: 0.5650
Epoch 4/23
311/311 - 246s - loss: 0.6799 - accuracy: 0.5607 - macro_f1: 0.5698 - val_loss: 0.6839 - val_accuracy: 0.5380 - val_macro_f1: 0.4626
Epoch 5/23
311/311 - 247s - loss: 0.6745 - accuracy: 0.5755 - macro_f1: 0.5818 - val_loss: 0.6711 - val_accuracy: 0.5845 - val_macro_f1: 0.5688
Epoch 6/23
311/311 - 246s - loss: 0.6602 - accuracy: 0.6035 - macro_f1: 0.5983 - val_loss: 0.6558 - val_accuracy: 0.6094 - val_macro_f1: 0.5776
Epoch 7/23
311/311 - 247s - loss: 0.6455 - accuracy: 0.6259 - macro_f1: 0.6276 - val_loss: 0.6455 - val_accuracy: 0.6260 - val_macro_f1: 0.6056
Epoch 8/23
311/311 - 247s - loss: 0.6371 - accuracy: 0.6377 - macro_f1: 0.6454 - val_loss: 0.6282 - val_accuracy: 0.6509 - val_macro_f1: 0.6896
Epoch 9/23
311/311 - 247s - loss: 0.6317 - accuracy: 0.6438 - macro_f1: 0.6531 - val_loss: 0.6372 - val_accuracy: 0.6377 - val_macro_f1: 0.6296
Epoch 10/23
311/311 - 248s - loss: 0.6295 - accuracy: 0.6466 - macro_f1: 0.6558 - val_loss: 0.6204 - val_accuracy: 0.6572 - val_macro_f1: 0.6924
Epoch 11/23
311/311 - 248s - loss: 0.6271 - accuracy: 0.6485 - macro_f1: 0.6581 - val_loss: 0.6197 - val_accuracy: 0.6571 - val_macro_f1: 0.6853
Epoch 12/23
311/311 - 249s - loss: 0.6249 - accuracy: 0.6521 - macro_f1: 0.6628 - val_loss: 0.6214 - val_accuracy: 0.6549 - val_macro_f1: 0.6656
Epoch 13/23
311/311 - 249s - loss: 0.6210 - accuracy: 0.6551 - macro_f1: 0.6662 - val_loss: 0.6443 - val_accuracy: 0.6222 - val_macro_f1: 0.5808
Epoch 14/23
311/311 - 249s - loss: 0.6175 - accuracy: 0.6595 - macro_f1: 0.6723 - val_loss: 0.6266 - val_accuracy: 0.6475 - val_macro_f1: 0.6409
Epoch 15/23
311/311 - 249s - loss: 0.6162 - accuracy: 0.6598 - macro_f1: 0.6716 - val_loss: 0.6140 - val_accuracy: 0.6648 - val_macro_f1: 0.6981
Epoch 16/23
311/311 - 249s - loss: 0.6154 - accuracy: 0.6607 - macro_f1: 0.6729 - val_loss: 0.6178 - val_accuracy: 0.6577 - val_macro_f1: 0.6727
Epoch 17/23
311/311 - 250s - loss: 0.6103 - accuracy: 0.6667 - macro_f1: 0.6808 - val_loss: 0.6109 - val_accuracy: 0.6674 - val_macro_f1: 0.7125
Epoch 18/23
311/311 - 250s - loss: 0.6113 - accuracy: 0.6657 - macro_f1: 0.6781 - val_loss: 0.6292 - val_accuracy: 0.6434 - val_macro_f1: 0.6234
Epoch 19/23
311/311 - 250s - loss: 0.6098 - accuracy: 0.6674 - macro_f1: 0.6793 - val_loss: 0.6107 - val_accuracy: 0.6659 - val_macro_f1: 0.6881
Epoch 20/23
311/311 - 250s - loss: 0.6091 - accuracy: 0.6672 - macro_f1: 0.6795 - val_loss: 0.6198 - val_accuracy: 0.6551 - val_macro_f1: 0.6494
Epoch 21/23
311/311 - 250s - loss: 0.6060 - accuracy: 0.6706 - macro_f1: 0.6828 - val_loss: 0.6068 - val_accuracy: 0.6714 - val_macro_f1: 0.6981
Epoch 22/23
311/311 - 250s - loss: 0.5986 - accuracy: 0.6790 - macro_f1: 0.6946 - val_loss: 0.6196 - val_accuracy: 0.6527 - val_macro_f1: 0.6440
Epoch 23/23
311/311 - 250s - loss: 0.5971 - accuracy: 0.6789 - macro_f1: 0.6931 - val_loss: 0.6058 - val_accuracy: 0.6712 - val_macro_f1: 0.7044
Running cyclical learning rate for Microglia_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.2.
In evaluation mode.
There 23044 positives and 18546 negatives.
42/42 - 8s
Accuracy: 0.6668003645443832. 
f1_score: 0.6710069545488028.
roc_auc: 0.7283092596193914.
prc_auc: 0.7563310068288756.
Running cyclical learning rate for Microglia_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.25.
In training mode.
There 171186 positives and 139774 negatives.
There 23044 positives and 18546 negatives.
Epoch 1/23
311/311 - 247s - loss: 0.6916 - accuracy: 0.5133 - macro_f1: 0.4974 - val_loss: 0.6936 - val_accuracy: 0.5015 - val_macro_f1: 0.3496
Epoch 2/23
311/311 - 244s - loss: 0.6853 - accuracy: 0.5366 - macro_f1: 0.5155 - val_loss: 0.6875 - val_accuracy: 0.5374 - val_macro_f1: 0.5068
Epoch 3/23
311/311 - 244s - loss: 0.6790 - accuracy: 0.5624 - macro_f1: 0.5654 - val_loss: 0.6741 - val_accuracy: 0.5766 - val_macro_f1: 0.5697
Epoch 4/23
311/311 - 245s - loss: 0.6613 - accuracy: 0.6008 - macro_f1: 0.5977 - val_loss: 0.6579 - val_accuracy: 0.6054 - val_macro_f1: 0.5704
Epoch 5/23
311/311 - 247s - loss: 0.6445 - accuracy: 0.6282 - macro_f1: 0.6326 - val_loss: 0.6516 - val_accuracy: 0.6143 - val_macro_f1: 0.5695
Epoch 6/23
311/311 - 247s - loss: 0.6359 - accuracy: 0.6387 - macro_f1: 0.6464 - val_loss: 0.6479 - val_accuracy: 0.6233 - val_macro_f1: 0.5931
Epoch 7/23
311/311 - 247s - loss: 0.6316 - accuracy: 0.6443 - macro_f1: 0.6543 - val_loss: 0.6302 - val_accuracy: 0.6481 - val_macro_f1: 0.6609
Epoch 8/23
311/311 - 247s - loss: 0.6289 - accuracy: 0.6470 - macro_f1: 0.6565 - val_loss: 0.6589 - val_accuracy: 0.6001 - val_macro_f1: 0.5248
Epoch 9/23
311/311 - 247s - loss: 0.6281 - accuracy: 0.6490 - macro_f1: 0.6581 - val_loss: 0.6247 - val_accuracy: 0.6562 - val_macro_f1: 0.6902
Epoch 10/23
311/311 - 247s - loss: 0.6246 - accuracy: 0.6520 - macro_f1: 0.6632 - val_loss: 0.6187 - val_accuracy: 0.6596 - val_macro_f1: 0.6976
Epoch 11/23
311/311 - 247s - loss: 0.6225 - accuracy: 0.6541 - macro_f1: 0.6653 - val_loss: 0.6197 - val_accuracy: 0.6576 - val_macro_f1: 0.6777
Epoch 12/23
311/311 - 248s - loss: 0.6188 - accuracy: 0.6586 - macro_f1: 0.6720 - val_loss: 0.6407 - val_accuracy: 0.6309 - val_macro_f1: 0.5965
Epoch 13/23
311/311 - 248s - loss: 0.6185 - accuracy: 0.6580 - macro_f1: 0.6700 - val_loss: 0.6321 - val_accuracy: 0.6402 - val_macro_f1: 0.6233
Epoch 14/23
311/311 - 248s - loss: 0.6169 - accuracy: 0.6596 - macro_f1: 0.6715 - val_loss: 0.6346 - val_accuracy: 0.6388 - val_macro_f1: 0.6411
Epoch 15/23
311/311 - 248s - loss: 0.6150 - accuracy: 0.6617 - macro_f1: 0.6750 - val_loss: 0.6358 - val_accuracy: 0.6353 - val_macro_f1: 0.6097
Epoch 16/23
311/311 - 248s - loss: 0.6116 - accuracy: 0.6654 - macro_f1: 0.6791 - val_loss: 0.6145 - val_accuracy: 0.6637 - val_macro_f1: 0.6870
Epoch 17/23
311/311 - 249s - loss: 0.6134 - accuracy: 0.6630 - macro_f1: 0.6751 - val_loss: 0.6669 - val_accuracy: 0.5993 - val_macro_f1: 0.5129
Epoch 18/23
311/311 - 249s - loss: 0.6119 - accuracy: 0.6644 - macro_f1: 0.6768 - val_loss: 0.6296 - val_accuracy: 0.6431 - val_macro_f1: 0.6259
Epoch 19/23
311/311 - 249s - loss: 0.6081 - accuracy: 0.6685 - macro_f1: 0.6819 - val_loss: 0.6401 - val_accuracy: 0.6338 - val_macro_f1: 0.5994
Epoch 20/23
311/311 - 249s - loss: 0.6062 - accuracy: 0.6706 - macro_f1: 0.6855 - val_loss: 0.6094 - val_accuracy: 0.6695 - val_macro_f1: 0.6892
Epoch 21/23
311/311 - 249s - loss: 0.6060 - accuracy: 0.6703 - macro_f1: 0.6838 - val_loss: 0.6149 - val_accuracy: 0.6604 - val_macro_f1: 0.6638
Epoch 22/23
311/311 - 249s - loss: 0.6051 - accuracy: 0.6726 - macro_f1: 0.6857 - val_loss: 0.6261 - val_accuracy: 0.6471 - val_macro_f1: 0.6358
Epoch 23/23
311/311 - 249s - loss: 0.6051 - accuracy: 0.6706 - macro_f1: 0.6814 - val_loss: 0.6116 - val_accuracy: 0.6676 - val_macro_f1: 0.7040
Running cyclical learning rate for Microglia_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.25.
In evaluation mode.
There 23044 positives and 18546 negatives.
42/42 - 8s
Accuracy: 0.661914386729316. 
f1_score: 0.6669089350309886.
roc_auc: 0.7204480857732243.
prc_auc: 0.7473110844955256.
Running cyclical learning rate for Microglia_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.3.
In training mode.
There 171186 positives and 139774 negatives.
There 23044 positives and 18546 negatives.
Epoch 1/23
311/311 - 248s - loss: 0.6918 - accuracy: 0.5110 - macro_f1: 0.4653 - val_loss: 0.6943 - val_accuracy: 0.4939 - val_macro_f1: 0.2960
Epoch 2/23
311/311 - 245s - loss: 0.6875 - accuracy: 0.5258 - macro_f1: 0.4660 - val_loss: 0.6888 - val_accuracy: 0.5207 - val_macro_f1: 0.4361
Epoch 3/23
311/311 - 245s - loss: 0.6793 - accuracy: 0.5606 - macro_f1: 0.5653 - val_loss: 0.6849 - val_accuracy: 0.5446 - val_macro_f1: 0.4336
Epoch 4/23
311/311 - 244s - loss: 0.6603 - accuracy: 0.6023 - macro_f1: 0.6018 - val_loss: 0.6528 - val_accuracy: 0.6177 - val_macro_f1: 0.5958
Epoch 5/23
311/311 - 244s - loss: 0.6456 - accuracy: 0.6259 - macro_f1: 0.6302 - val_loss: 0.6747 - val_accuracy: 0.5710 - val_macro_f1: 0.4498
Epoch 6/23
311/311 - 244s - loss: 0.6388 - accuracy: 0.6350 - macro_f1: 0.6422 - val_loss: 0.6378 - val_accuracy: 0.6436 - val_macro_f1: 0.6581
Epoch 7/23
311/311 - 244s - loss: 0.6328 - accuracy: 0.6432 - macro_f1: 0.6531 - val_loss: 0.6483 - val_accuracy: 0.6211 - val_macro_f1: 0.5806
Epoch 8/23
311/311 - 244s - loss: 0.6312 - accuracy: 0.6449 - macro_f1: 0.6543 - val_loss: 0.6306 - val_accuracy: 0.6503 - val_macro_f1: 0.6720
Epoch 9/23
311/311 - 244s - loss: 0.6281 - accuracy: 0.6473 - macro_f1: 0.6577 - val_loss: 0.6333 - val_accuracy: 0.6426 - val_macro_f1: 0.6377
Epoch 10/23
311/311 - 244s - loss: 0.6268 - accuracy: 0.6495 - macro_f1: 0.6601 - val_loss: 0.6729 - val_accuracy: 0.5799 - val_macro_f1: 0.4695
Epoch 11/23
311/311 - 244s - loss: 0.6243 - accuracy: 0.6517 - macro_f1: 0.6632 - val_loss: 0.6529 - val_accuracy: 0.6152 - val_macro_f1: 0.5571
Epoch 12/23
311/311 - 244s - loss: 0.6219 - accuracy: 0.6546 - macro_f1: 0.6665 - val_loss: 0.6365 - val_accuracy: 0.6371 - val_macro_f1: 0.6195
Epoch 13/23
311/311 - 245s - loss: 0.6197 - accuracy: 0.6572 - macro_f1: 0.6694 - val_loss: 0.6546 - val_accuracy: 0.6105 - val_macro_f1: 0.5511
Epoch 14/23
311/311 - 246s - loss: 0.6186 - accuracy: 0.6582 - macro_f1: 0.6709 - val_loss: 0.6533 - val_accuracy: 0.6151 - val_macro_f1: 0.5560
Epoch 15/23
311/311 - 246s - loss: 0.6182 - accuracy: 0.6586 - macro_f1: 0.6714 - val_loss: 0.6346 - val_accuracy: 0.6379 - val_macro_f1: 0.6112
Epoch 16/23
311/311 - 246s - loss: 0.6156 - accuracy: 0.6615 - macro_f1: 0.6746 - val_loss: 0.6499 - val_accuracy: 0.6151 - val_macro_f1: 0.5546
Epoch 17/23
311/311 - 246s - loss: 0.6145 - accuracy: 0.6630 - macro_f1: 0.6758 - val_loss: 0.6741 - val_accuracy: 0.5796 - val_macro_f1: 0.4607
Epoch 18/23
311/311 - 246s - loss: 0.6175 - accuracy: 0.6586 - macro_f1: 0.6694 - val_loss: 0.6376 - val_accuracy: 0.6342 - val_macro_f1: 0.6069
Epoch 19/23
311/311 - 246s - loss: 0.6109 - accuracy: 0.6665 - macro_f1: 0.6805 - val_loss: 0.6258 - val_accuracy: 0.6491 - val_macro_f1: 0.6415
Epoch 20/23
311/311 - 246s - loss: 0.6123 - accuracy: 0.6655 - macro_f1: 0.6788 - val_loss: 0.6528 - val_accuracy: 0.6119 - val_macro_f1: 0.5424
Epoch 21/23
311/311 - 246s - loss: 0.6120 - accuracy: 0.6646 - macro_f1: 0.6772 - val_loss: 0.6691 - val_accuracy: 0.5971 - val_macro_f1: 0.5083
Epoch 22/23
311/311 - 246s - loss: 0.6089 - accuracy: 0.6677 - macro_f1: 0.6811 - val_loss: 0.6223 - val_accuracy: 0.6515 - val_macro_f1: 0.6449
Epoch 23/23
311/311 - 246s - loss: 0.6060 - accuracy: 0.6708 - macro_f1: 0.6850 - val_loss: 0.6282 - val_accuracy: 0.6463 - val_macro_f1: 0.6250
Running cyclical learning rate for Microglia_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.01 - 0.1.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.3.
In evaluation mode.
There 23044 positives and 18546 negatives.
42/42 - 8s
Accuracy: 0.6598508804082113. 
f1_score: 0.6431321565455266.
roc_auc: 0.7309536353571175.
prc_auc: 0.759015252469009.
