Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.001 - 0.01.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.05.
In training mode.
There 380766 positives and 283508 negatives.
There 48948 positives and 35420 negatives.
Epoch 1/23
665/665 - 525s - loss: 0.6885 - accuracy: 0.5425 - macro_f1: 0.5622 - val_loss: 0.6808 - val_accuracy: 0.5636 - val_macro_f1: 0.5864
Epoch 2/23
665/665 - 526s - loss: 0.6683 - accuracy: 0.5926 - macro_f1: 0.6443 - val_loss: 0.6527 - val_accuracy: 0.6212 - val_macro_f1: 0.6828
Epoch 3/23
665/665 - 529s - loss: 0.6510 - accuracy: 0.6178 - macro_f1: 0.6552 - val_loss: 0.6669 - val_accuracy: 0.5923 - val_macro_f1: 0.5777
Epoch 4/23
665/665 - 530s - loss: 0.6411 - accuracy: 0.6309 - macro_f1: 0.6637 - val_loss: 0.6533 - val_accuracy: 0.6105 - val_macro_f1: 0.6153
Epoch 5/23
665/665 - 529s - loss: 0.6317 - accuracy: 0.6424 - macro_f1: 0.6740 - val_loss: 0.7055 - val_accuracy: 0.5636 - val_macro_f1: 0.4731
Epoch 6/23
665/665 - 530s - loss: 0.6211 - accuracy: 0.6544 - macro_f1: 0.6848 - val_loss: 0.6164 - val_accuracy: 0.6582 - val_macro_f1: 0.6788
Epoch 7/23
665/665 - 531s - loss: 0.6092 - accuracy: 0.6673 - macro_f1: 0.6979 - val_loss: 0.6005 - val_accuracy: 0.6763 - val_macro_f1: 0.7026
Epoch 8/23
665/665 - 534s - loss: 0.6006 - accuracy: 0.6760 - macro_f1: 0.7054 - val_loss: 0.5971 - val_accuracy: 0.6862 - val_macro_f1: 0.7696
Epoch 9/23
665/665 - 534s - loss: 0.5935 - accuracy: 0.6833 - macro_f1: 0.7132 - val_loss: 0.6201 - val_accuracy: 0.6565 - val_macro_f1: 0.6522
Epoch 10/23
665/665 - 534s - loss: 0.5874 - accuracy: 0.6894 - macro_f1: 0.7190 - val_loss: 0.6401 - val_accuracy: 0.6359 - val_macro_f1: 0.6061
Epoch 11/23
665/665 - 534s - loss: 0.5806 - accuracy: 0.6954 - macro_f1: 0.7255 - val_loss: 0.5828 - val_accuracy: 0.6928 - val_macro_f1: 0.7115
Epoch 12/23
665/665 - 535s - loss: 0.5736 - accuracy: 0.7027 - macro_f1: 0.7328 - val_loss: 0.5567 - val_accuracy: 0.7206 - val_macro_f1: 0.7782
Epoch 13/23
665/665 - 535s - loss: 0.5680 - accuracy: 0.7076 - macro_f1: 0.7376 - val_loss: 0.6185 - val_accuracy: 0.6637 - val_macro_f1: 0.6501
Epoch 14/23
665/665 - 536s - loss: 0.5628 - accuracy: 0.7116 - macro_f1: 0.7414 - val_loss: 0.5480 - val_accuracy: 0.7246 - val_macro_f1: 0.7814
Epoch 15/23
665/665 - 536s - loss: 0.5565 - accuracy: 0.7174 - macro_f1: 0.7472 - val_loss: 0.6538 - val_accuracy: 0.6422 - val_macro_f1: 0.6056
Epoch 16/23
665/665 - 536s - loss: 0.5550 - accuracy: 0.7188 - macro_f1: 0.7478 - val_loss: 0.5474 - val_accuracy: 0.7273 - val_macro_f1: 0.7669
Epoch 17/23
665/665 - 536s - loss: 0.5485 - accuracy: 0.7244 - macro_f1: 0.7539 - val_loss: 0.5384 - val_accuracy: 0.7323 - val_macro_f1: 0.7747
Epoch 18/23
665/665 - 537s - loss: 0.5469 - accuracy: 0.7256 - macro_f1: 0.7549 - val_loss: 0.5659 - val_accuracy: 0.7108 - val_macro_f1: 0.7285
Epoch 19/23
665/665 - 536s - loss: 0.5478 - accuracy: 0.7250 - macro_f1: 0.7534 - val_loss: 0.5488 - val_accuracy: 0.7250 - val_macro_f1: 0.7544
Epoch 20/23
665/665 - 537s - loss: 0.5385 - accuracy: 0.7326 - macro_f1: 0.7615 - val_loss: 0.5815 - val_accuracy: 0.6986 - val_macro_f1: 0.7043
Epoch 21/23
665/665 - 537s - loss: 0.5362 - accuracy: 0.7342 - macro_f1: 0.7627 - val_loss: 0.5458 - val_accuracy: 0.7264 - val_macro_f1: 0.7547
Epoch 22/23
665/665 - 537s - loss: 0.5316 - accuracy: 0.7372 - macro_f1: 0.7655 - val_loss: 0.5311 - val_accuracy: 0.7395 - val_macro_f1: 0.7807
Epoch 23/23
665/665 - 537s - loss: 0.5265 - accuracy: 0.7411 - macro_f1: 0.7694 - val_loss: 0.5533 - val_accuracy: 0.7204 - val_macro_f1: 0.7402
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.001 - 0.01.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.05.
In evaluation mode.
Traceback (most recent call last):
  File "train_singleTask_CNN_classifier_OCP.py", line 274, in <module>
    main(args)
  File "train_singleTask_CNN_classifier_OCP.py", line 197, in main
    (x_valid, y_valid, ids_valid) = encode_sequence2(args.valid_fasta_pos, args.valid_fasta_neg, size = args.seq_length, shuffleOff = True)
TypeError: encode_sequence2() got an unexpected keyword argument 'size'
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.001 - 0.01.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.1.
In training mode.
There 380766 positives and 283508 negatives.
There 48948 positives and 35420 negatives.
Epoch 1/23
665/665 - 525s - loss: 0.6879 - accuracy: 0.5455 - macro_f1: 0.5781 - val_loss: 0.6658 - val_accuracy: 0.6059 - val_macro_f1: 0.6946
Epoch 2/23
665/665 - 525s - loss: 0.6677 - accuracy: 0.5927 - macro_f1: 0.6414 - val_loss: 0.6530 - val_accuracy: 0.6176 - val_macro_f1: 0.6661
Epoch 3/23
665/665 - 524s - loss: 0.6520 - accuracy: 0.6164 - macro_f1: 0.6513 - val_loss: 0.6674 - val_accuracy: 0.5927 - val_macro_f1: 0.5791
Epoch 4/23
665/665 - 524s - loss: 0.6417 - accuracy: 0.6299 - macro_f1: 0.6637 - val_loss: 0.6300 - val_accuracy: 0.6471 - val_macro_f1: 0.6977
Epoch 5/23
665/665 - 524s - loss: 0.6334 - accuracy: 0.6410 - macro_f1: 0.6726 - val_loss: 0.6270 - val_accuracy: 0.6549 - val_macro_f1: 0.6963
Epoch 6/23
665/665 - 529s - loss: 0.6228 - accuracy: 0.6527 - macro_f1: 0.6841 - val_loss: 0.6713 - val_accuracy: 0.5805 - val_macro_f1: 0.5118
Epoch 7/23
665/665 - 532s - loss: 0.6136 - accuracy: 0.6629 - macro_f1: 0.6935 - val_loss: 0.5892 - val_accuracy: 0.6881 - val_macro_f1: 0.7450
Epoch 8/23
665/665 - 533s - loss: 0.6065 - accuracy: 0.6705 - macro_f1: 0.7007 - val_loss: 0.5906 - val_accuracy: 0.6865 - val_macro_f1: 0.7212
Epoch 9/23
665/665 - 533s - loss: 0.5966 - accuracy: 0.6808 - macro_f1: 0.7112 - val_loss: 0.6174 - val_accuracy: 0.6579 - val_macro_f1: 0.6579
Epoch 10/23
665/665 - 533s - loss: 0.5921 - accuracy: 0.6852 - macro_f1: 0.7156 - val_loss: 0.5745 - val_accuracy: 0.7098 - val_macro_f1: 0.7628
Epoch 11/23
665/665 - 533s - loss: 0.5845 - accuracy: 0.6921 - macro_f1: 0.7229 - val_loss: 0.6017 - val_accuracy: 0.6749 - val_macro_f1: 0.6788
Epoch 12/23
665/665 - 533s - loss: 0.5799 - accuracy: 0.6965 - macro_f1: 0.7269 - val_loss: 0.5601 - val_accuracy: 0.7166 - val_macro_f1: 0.7761
Epoch 13/23
665/665 - 533s - loss: 0.5748 - accuracy: 0.7012 - macro_f1: 0.7313 - val_loss: 0.5598 - val_accuracy: 0.7187 - val_macro_f1: 0.7594
Epoch 14/23
665/665 - 533s - loss: 0.5700 - accuracy: 0.7057 - macro_f1: 0.7359 - val_loss: 0.6289 - val_accuracy: 0.6514 - val_macro_f1: 0.6280
Epoch 15/23
665/665 - 534s - loss: 0.5680 - accuracy: 0.7071 - macro_f1: 0.7369 - val_loss: 0.5539 - val_accuracy: 0.7251 - val_macro_f1: 0.7706
Epoch 16/23
665/665 - 534s - loss: 0.5617 - accuracy: 0.7125 - macro_f1: 0.7426 - val_loss: 0.5506 - val_accuracy: 0.7246 - val_macro_f1: 0.7627
Epoch 17/23
665/665 - 533s - loss: 0.5581 - accuracy: 0.7157 - macro_f1: 0.7457 - val_loss: 0.5445 - val_accuracy: 0.7288 - val_macro_f1: 0.7674
Epoch 18/23
665/665 - 533s - loss: 0.5528 - accuracy: 0.7204 - macro_f1: 0.7505 - val_loss: 0.5482 - val_accuracy: 0.7282 - val_macro_f1: 0.7623
Epoch 19/23
665/665 - 534s - loss: 0.5522 - accuracy: 0.7212 - macro_f1: 0.7508 - val_loss: 0.6102 - val_accuracy: 0.6685 - val_macro_f1: 0.6511
Epoch 20/23
665/665 - 534s - loss: 0.5508 - accuracy: 0.7224 - macro_f1: 0.7515 - val_loss: 0.5559 - val_accuracy: 0.7172 - val_macro_f1: 0.7457
Epoch 21/23
665/665 - 535s - loss: 0.5470 - accuracy: 0.7255 - macro_f1: 0.7548 - val_loss: 0.5876 - val_accuracy: 0.6926 - val_macro_f1: 0.6930
Epoch 22/23
665/665 - 535s - loss: 0.5451 - accuracy: 0.7267 - macro_f1: 0.7556 - val_loss: 0.5556 - val_accuracy: 0.7205 - val_macro_f1: 0.7437
Epoch 23/23
665/665 - 535s - loss: 0.5341 - accuracy: 0.7357 - macro_f1: 0.7654 - val_loss: 0.5544 - val_accuracy: 0.7190 - val_macro_f1: 0.7379
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.001 - 0.01.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.1.
In evaluation mode.
Traceback (most recent call last):
  File "train_singleTask_CNN_classifier_OCP.py", line 274, in <module>
    main(args)
  File "train_singleTask_CNN_classifier_OCP.py", line 197, in main
    (x_valid, y_valid, ids_valid) = encode_sequence2(args.valid_fasta_pos, args.valid_fasta_neg, size = args.seq_length, shuffleOff = True)
TypeError: encode_sequence2() got an unexpected keyword argument 'size'
Running cyclical learning rate for MSN_D1_hgRmMm_enhVsNonEnhOrth.
One-cycle policy training for 23 epochs.
Learning rates range: 0.001 - 0.01.
Momentum rates range: 0.85 - 0.99.
Dropout: 0.15.
In training mode.
There 380766 positives and 283508 negatives.
There 48948 positives and 35420 negatives.
Epoch 1/23
665/665 - 524s - loss: 0.6903 - accuracy: 0.5317 - macro_f1: 0.5417 - val_loss: 0.6765 - val_accuracy: 0.5811 - val_macro_f1: 0.6346
Epoch 2/23
665/665 - 524s - loss: 0.6705 - accuracy: 0.5872 - macro_f1: 0.6354 - val_loss: 0.6705 - val_accuracy: 0.5869 - val_macro_f1: 0.6069
Epoch 3/23
665/665 - 525s - loss: 0.6536 - accuracy: 0.6136 - macro_f1: 0.6491 - val_loss: 0.6516 - val_accuracy: 0.6223 - val_macro_f1: 0.6727
Epoch 4/23
665/665 - 527s - loss: 0.6410 - accuracy: 0.6307 - macro_f1: 0.6645 - val_loss: 0.6269 - val_accuracy: 0.6524 - val_macro_f1: 0.7001
Epoch 5/23
665/665 - 528s - loss: 0.6329 - accuracy: 0.6412 - macro_f1: 0.6727 - val_loss: 0.6369 - val_accuracy: 0.6356 - val_macro_f1: 0.6475
Epoch 6/23
665/665 - 529s - loss: 0.6239 - accuracy: 0.6518 - macro_f1: 0.6826 - val_loss: 0.6619 - val_accuracy: 0.6108 - val_macro_f1: 0.5763
Epoch 7/23
665/665 - 532s - loss: 0.6135 - accuracy: 0.6635 - macro_f1: 0.6939 - val_loss: 0.6594 - val_accuracy: 0.6128 - val_macro_f1: 0.5725
Epoch 8/23
665/665 - 533s - loss: 0.6059 - accuracy: 0.6714 - macro_f1: 0.7019 - val_loss: 0.6120 - val_accuracy: 0.6635 - val_macro_f1: 0.6755
Epoch 9/23
665/665 - 533s - loss: 0.6006 - accuracy: 0.6775 - macro_f1: 0.7065 - val_loss: 0.6614 - val_accuracy: 0.6093 - val_macro_f1: 0.5550
Epoch 10/23
665/665 - 534s - loss: 0.5943 - accuracy: 0.6828 - macro_f1: 0.7125 - val_loss: 0.5903 - val_accuracy: 0.6875 - val_macro_f1: 0.7140
Epoch 11/23
665/665 - 534s - loss: 0.5877 - accuracy: 0.6891 - macro_f1: 0.7192 - val_loss: 0.5786 - val_accuracy: 0.7037 - val_macro_f1: 0.7380
Epoch 12/23
665/665 - 535s - loss: 0.5826 - accuracy: 0.6938 - macro_f1: 0.7238 - val_loss: 0.6757 - val_accuracy: 0.6060 - val_macro_f1: 0.5385
Epoch 13/23
665/665 - 535s - loss: 0.5795 - accuracy: 0.6973 - macro_f1: 0.7270 - val_loss: 0.6680 - val_accuracy: 0.5999 - val_macro_f1: 0.5226
Epoch 14/23
665/665 - 534s - loss: 0.5736 - accuracy: 0.7023 - macro_f1: 0.7328 - val_loss: 0.5884 - val_accuracy: 0.6913 - val_macro_f1: 0.7030
Epoch 15/23
665/665 - 535s - loss: 0.5714 - accuracy: 0.7044 - macro_f1: 0.7339 - val_loss: 0.6091 - val_accuracy: 0.6680 - val_macro_f1: 0.6579
Epoch 16/23
665/665 - 535s - loss: 0.5650 - accuracy: 0.7100 - macro_f1: 0.7404 - val_loss: 0.6292 - val_accuracy: 0.6511 - val_macro_f1: 0.6231
Epoch 17/23
665/665 - 535s - loss: 0.5622 - accuracy: 0.7125 - macro_f1: 0.7426 - val_loss: 0.5922 - val_accuracy: 0.6870 - val_macro_f1: 0.6895
Epoch 18/23
665/665 - 535s - loss: 0.5593 - accuracy: 0.7152 - macro_f1: 0.7451 - val_loss: 0.5914 - val_accuracy: 0.6872 - val_macro_f1: 0.6873
Epoch 19/23
665/665 - 535s - loss: 0.5587 - accuracy: 0.7158 - macro_f1: 0.7450 - val_loss: 0.5507 - val_accuracy: 0.7266 - val_macro_f1: 0.7685
Epoch 20/23
665/665 - 535s - loss: 0.5549 - accuracy: 0.7188 - macro_f1: 0.7487 - val_loss: 0.6265 - val_accuracy: 0.6539 - val_macro_f1: 0.6227
Epoch 21/23
665/665 - 535s - loss: 0.5574 - accuracy: 0.7162 - macro_f1: 0.7447 - val_loss: 0.5664 - val_accuracy: 0.7103 - val_macro_f1: 0.7273
Epoch 22/23
665/665 - 535s - loss: 0.5508 - accuracy: 0.7219 - macro_f1: 0.7510 - val_loss: 0.5464 - val_accuracy: 0.7266 - val_macro_f1: 0.7568
Epoch 23/23
665/665 - 535s - loss: 0.5443 - accuracy: 0.7279 - macro_f1: 0.7572 - val_loss: 0.5402 - val_accuracy: 0.7350 - val_macro_f1: 0.7711
  File "train_singleTask_CNN_classifier_OCP.py", line 115
    df = pd.DataFrame(vars(args), index=[0])
     ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 115
    df = pd.DataFrame(vars(args), index=[0])
     ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 115
    df = pd.DataFrame(vars(args), index=[0])
     ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 115
    df = pd.DataFrame(vars(args), index=[0])
     ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 115
    df = pd.DataFrame(vars(args), index=[0])
     ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 115
    df = pd.DataFrame(vars(args), index=[0])
     ^
IndentationError: expected an indented block
  File "train_singleTask_CNN_classifier_OCP.py", line 115
    df = pd.DataFrame(vars(args), index=[0])
     ^
IndentationError: expected an indented block
